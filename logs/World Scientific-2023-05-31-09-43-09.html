<html lang="en" class="pb-page" data-request-id="9a6117c6-8967-4b9e-ad79-0e0da2d4d50e"><head data-pb-dropzone="head"><meta name="pbContext" content=";website:website:wspc-site;requestedJournal:journal:books;csubtype:string:Edited Collection;wgroup:string:WSPC website Group;page:string:Book Page;issue:issue:10.1142/10153;ctype:string:Book Content;journal:journal:books;pageGroup:string:Publication Pages">

<title>Pattern Recognition and Big Data</title>





<meta charset="UTF-8">
<meta name="robots" content="noarchive">
















<meta name="viewport" content="width=device-width,initial-scale=1">



























    

    
    

    
    
    
    
        
            
            
            
                
            
        
    

<link rel="stylesheet" type="text/css" href="/wro/maj1~product.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,600,700"><link rel="stylesheet" href="/products/wspc/releasedAssets/css/build-3bda01e7fb38cad777f6.css"><link rel="stylesheet" href="/products/wspc/releasedAssets/css/print-3bda01e7fb38cad777f6.css" media="print">



<script async="" src="https://www.clarity.ms/s/0.7.8/clarity.js"></script><script async="" src="https://www.clarity.ms/tag/uet/97023831"></script><script src="//d1l6p2sc9645hc.cloudfront.net/tracker.js"></script><script async="" src="https://s.pinimg.com/ct/lib/main.b68cecd9.js"></script><script type="text/javascript" async="" src="https://www.googletagmanager.com/gtag/js?id=G-CHQ29MQVMT&amp;l=dataLayer&amp;cx=c"></script><script type="text/javascript" id="sendinblue-js" async="" src="https://sibautomation.com/sa.js?key=2vi0d2rds5mfq4f27x2surwv"></script><script src="https://connect.facebook.net/signals/config/731609284183339?v=2.9.104&amp;r=stable" async=""></script><script src="https://connect.facebook.net/signals/config/162493725769742?v=2.9.104&amp;r=stable" async=""></script><script async="" src="https://connect.facebook.net/en_US/fbevents.js"></script><script async="" src="https://a.quora.com/qevents.js"></script><script type="text/javascript" async="" src="https://s.pinimg.com/ct/core.js"></script><script type="text/javascript" async="" src="https://www.redditstatic.com/ads/pixel.js"></script><script type="text/javascript" async="" src="https://static.ads-twitter.com/uwt.js"></script><script type="text/javascript" async="" src="https://bat.bing.com/bat.js"></script><script type="text/javascript" async="" src="https://snap.licdn.com/li.lms-analytics/insight.min.js"></script><script async="" src="https://www.googletagmanager.com/gtm.js?id=GTM-NVG6FP"></script><script async="" src="//www.google-analytics.com/analytics.js"></script><script async="" src="https://chimpstatic.com/mcjs-connected/js/users/5a49d15f21f692f9e1dbd7609/a628eda248f5b854779d5e8ea.js"></script><script type="text/javascript" src="/templates/jsp/js/jquery-3.1.1.min.js"></script>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<script id="mcjs">!function(c,h,i,m,p){m=c.createElement(h),p=c.getElementsByTagName(h)[0],m.async=1,m.src=i,p.parentNode.insertBefore(m,p)}(document,"script","https://chimpstatic.com/mcjs-connected/js/users/5a49d15f21f692f9e1dbd7609/a628eda248f5b854779d5e8ea.js");</script><script type="text/javascript">
                (function (i, s, o, g, r, a, m) {
                    i['GoogleAnalyticsObject'] = r;
                    i[r] = i[r] || function () {
                        (i[r].q = i[r].q || []).push(arguments)
                    }, i[r].l = 1 * new Date();
                    a = s.createElement(o), m = s.getElementsByTagName(o)[0];
                    a.async = 1;
                    a.src = g;
                    m.parentNode.insertBefore(a, m)
                })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
                ga('create', 'UA-498241-2'
                    
                    , 'auto'
                    );
                
                ga('send', 'pageview');
            </script>
            <link rel="canonical" href="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/worldscibooks/10.1142/10153">
        




<meta http-equiv="origin-trial" content="AymqwRC7u88Y4JPvfIF2F37QKylC04248hLCdJAsh8xgOfe/dVJPV3XS3wLFca1ZMVOtnBfVjaCMTVudWM//5g4AAAB7eyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGV0YWdtYW5hZ2VyLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjk1MTY3OTk5LCJpc1RoaXJkUGFydHkiOnRydWV9"><script type="text/javascript" async="" src="https://googleads.g.doubleclick.net/pagead/viewthroughconversion/1071980501/?random=1685497324136&amp;cv=11&amp;fst=1685497324136&amp;bg=ffffff&amp;guid=ON&amp;async=1&amp;gtm=45He35o0&amp;u_w=2048&amp;u_h=1152&amp;url=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153&amp;hn=www.googleadservices.com&amp;frm=0&amp;tiba=Pattern%20Recognition%20and%20Big%20Data&amp;auid=1863224073.1685497091&amp;uaa=x86&amp;uab=64&amp;uafvl=Google%2520Chrome%3B113.0.5672.127%7CChromium%3B113.0.5672.127%7CNot-A.Brand%3B24.0.0.0&amp;uamb=0&amp;uap=Windows&amp;uapv=7.0.0&amp;uaw=0&amp;rfmt=3&amp;fmt=4"></script><script src="https://bat.bing.com/p/action/97023831.js" type="text/javascript" async="" data-ueto="ueto_96b0c5251b"></script><script attributionsrc="" type="text/javascript" async="" src="https://googleads.g.doubleclick.net/pagead/viewthroughconversion/753855465/?random=1685497324268&amp;cv=9&amp;fst=1685497324268&amp;num=1&amp;guid=ON&amp;resp=GooglemKTybQhCsO&amp;eid=376635471%2C466465925&amp;u_h=1152&amp;u_w=2048&amp;u_ah=1112&amp;u_aw=2048&amp;u_cd=24&amp;u_his=1&amp;u_tz=480&amp;u_java=false&amp;u_nplug=5&amp;u_nmime=2&amp;sendb=1&amp;ig=1&amp;frm=0&amp;url=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153&amp;tiba=Pattern%20Recognition%20and%20Big%20Data&amp;hn=www.googleadservices.com&amp;uaa=x86&amp;uab=64&amp;uam=&amp;uap=Windows&amp;uapv=7.0.0&amp;uaw=0&amp;uafvl=Google%2520Chrome%3B113.0.5672.127%7CChromium%3B113.0.5672.127%7CNot-A.Brand%3B24.0.0.0&amp;async=1&amp;rfmt=3&amp;fmt=4"></script><meta http-equiv="origin-trial" content="AymqwRC7u88Y4JPvfIF2F37QKylC04248hLCdJAsh8xgOfe/dVJPV3XS3wLFca1ZMVOtnBfVjaCMTVudWM//5g4AAAB7eyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGV0YWdtYW5hZ2VyLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjk1MTY3OTk5LCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="AxMeahpLO9nDB/vFXFMGOd/JLhKWx/mOjErAi0qFXDzWuMSYoKpfjFtFfQWMCx+Qg39PMxDJHSLlAJF/H8rtmAwAAABveyJvcmlnaW4iOiJodHRwczovL3MucGluaW1nLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjgwNjUyNzk5LCJpc1RoaXJkUGFydHkiOnRydWV9"><script type="text/javascript" charset="utf-8" async="" defer="" src="https://front.optimonk.com/public/175445/js/preload.js"></script><script charset="utf-8" src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/products/wspc/releasedAssets/js/vendors~dynamic-imports-e4f26383ae1798a15155.js"></script><script src="https://static.addtoany.com/menu/modules/core.26680508.js" type="module"></script><style></style><script async="" src="//api.b2c.com/s/pp.js"></script><style type="text/css">.a2a_hide{display:none}.a2a_logo_color{background-color:#0166ff}.a2a_menu,.a2a_menu *{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;float:none;margin:0;padding:0;position:static;height:auto;width:auto}.a2a_menu{border-radius:6px;display:none;direction:ltr;background:#FFF;font:16px sans-serif-light,HelveticaNeue-Light,"Helvetica Neue Light","Helvetica Neue",Arial,Helvetica,"Liberation Sans",sans-serif;color:#000;line-height:12px;border:1px solid #CCC;vertical-align:baseline;overflow:hidden}.a2a_mini{min-width:200px;position:absolute;width:300px;z-index:9999997}.a2a_overlay{display:none;background:#616c7deb;backdrop-filter:blur(4px);-webkit-backdrop-filter:blur(4px);position:fixed;top:0;right:0;left:0;bottom:0;z-index:9999998;-webkit-tap-highlight-color:transparent;transition:opacity .14s,backdrop-filter .14s}.a2a_full{background:#FFF;border:1px solid #FFF;box-shadow:#2a2a2a1a 0 0 20px 10px;height:auto;height:calc(320px);top:15%;left:50%;margin-left:-320px;position:fixed;text-align:center;width:640px;z-index:9999999;transition:transform .14s,opacity .14s}.a2a_full_footer,.a2a_full_header,.a2a_full_services{border:0;margin:0;padding:12px;box-sizing:border-box}.a2a_full_header{padding-bottom:8px}.a2a_full_services{height:280px;overflow-y:scroll;padding:0 12px;-webkit-overflow-scrolling:touch}.a2a_full_services .a2a_i{display:inline-block;float:none;width:181px;width:calc(33.334% - 18px)}div.a2a_full_footer{font-size:12px;text-align:center;padding:8px 14px}div.a2a_full_footer a,div.a2a_full_footer a:visited{display:inline;font-size:12px;line-height:14px;padding:8px 14px}div.a2a_full_footer a:focus,div.a2a_full_footer a:hover{background:0 0;border:0;color:#0166FF}div.a2a_full_footer a span.a2a_s_a2a,div.a2a_full_footer a span.a2a_w_a2a{background-size:14px;border-radius:3px;display:inline-block;height:14px;line-height:14px;margin:0 3px 0 0;vertical-align:top;width:14px}.a2a_modal{height:0;left:50%;margin-left:-320px;position:fixed;text-align:center;top:15%;width:640px;z-index:9999999;transition:transform .14s,opacity .14s;-webkit-tap-highlight-color:transparent}.a2a_modal_body{background:0 0;border:0;font:24px sans-serif-light,HelveticaNeue-Light,"Helvetica Neue Light","Helvetica Neue",Arial,Helvetica,"Liberation Sans",sans-serif;position:relative;height:auto;width:auto}.a2a_thanks{color:#fff;height:auto;margin-top:20px;width:auto}.a2a_thanks>div:first-child{margin:0 0 40px 0}.a2a_thanks div *{height:inherit}#a2a_copy_link{background:#FFF;border:1px solid #FFF;cursor:pointer;margin-top:15%}span.a2a_s_link#a2a_copy_link_icon,span.a2a_w_link#a2a_copy_link_icon{background-size:48px;border-radius:0;display:inline-block;height:48px;left:0;line-height:48px;margin:0 3px 0 0;position:absolute;vertical-align:top;width:48px}#a2a_modal input#a2a_copy_link_text{background-color:transparent;border:0;color:#2A2A2A;cursor:pointer;font:inherit;height:48px;left:62px;max-width:initial;padding:0;position:relative;width:564px;width:calc(100% - 76px)}#a2a_copy_link_copied{background-color:#0166ff;color:#fff;display:none;font:inherit;font-size:16px;margin-top:1px;padding:3px 8px}@media (prefers-color-scheme:dark){.a2a_menu a,.a2a_menu a.a2a_i,.a2a_menu a.a2a_i:visited,.a2a_menu a.a2a_more,i.a2a_i{border-color:#2a2a2a!important;color:#fff!important}.a2a_menu a.a2a_i:active,.a2a_menu a.a2a_i:focus,.a2a_menu a.a2a_i:hover,.a2a_menu a.a2a_more:active,.a2a_menu a.a2a_more:focus,.a2a_menu a.a2a_more:hover,.a2a_menu_find_container{border-color:#444!important;background-color:#444!important}.a2a_menu:not(.a2a_thanks){background-color:#2a2a2a;border-color:#2a2a2a}.a2a_menu_find{color:#fff!important}.a2a_menu span.a2a_s_find svg{background-color:transparent!important}.a2a_menu span.a2a_s_find svg path{fill:#fff!important}.a2a_full{box-shadow:#00000066 0 0 20px 10px}.a2a_overlay{background-color:#373737eb}}@media print{.a2a_floating_style,.a2a_menu,.a2a_overlay{visibility:hidden}}@keyframes a2aFadeIn{from{opacity:0}to{opacity:1}}.a2a_starting{opacity:0}.a2a_starting.a2a_full,.a2a_starting.a2a_modal{transform:scale(.8)}@media (max-width:639px){.a2a_full{border-radius:0;top:15%;left:0;margin-left:auto;width:100%}.a2a_modal{left:0;margin-left:10px;width:calc(100% - 20px)}}@media (min-width:318px) and (max-width:437px){.a2a_full .a2a_full_services .a2a_i{width:calc(50% - 18px)}}@media (max-width:317px){.a2a_full .a2a_full_services .a2a_i{width:calc(100% - 18px)}}@media (max-height:436px){.a2a_full{bottom:40px;height:auto;top:40px}}@media (max-height:550px){.a2a_modal{top:30px}}@media (max-height:360px){.a2a_modal{top:20px}.a2a_thanks>div:first-child{margin-bottom:20px}}.a2a_menu a{color:#0166FF;text-decoration:none;font:16px sans-serif-light,HelveticaNeue-Light,"Helvetica Neue Light","Helvetica Neue",Arial,Helvetica,"Liberation Sans",sans-serif;line-height:14px;height:auto;width:auto;outline:0}.a2a_menu a.a2a_i:visited,.a2a_menu a.a2a_more{color:#0166FF}.a2a_menu a.a2a_i:active,.a2a_menu a.a2a_i:focus,.a2a_menu a.a2a_i:hover,.a2a_menu a.a2a_more:active,.a2a_menu a.a2a_more:focus,.a2a_menu a.a2a_more:hover{color:#2A2A2A;border-color:#EEE;border-style:solid;background-color:#EEE;text-decoration:none}.a2a_menu span.a2a_s_find{background-size:24px;height:24px;left:8px;position:absolute;top:7px;width:24px}.a2a_menu span.a2a_s_find svg{background-color:#FFF}.a2a_menu span.a2a_s_find svg path{fill:#CCC}#a2a_menu_container{display:inline-block}.a2a_menu_find_container{border:1px solid #CCC;border-radius:6px;padding:2px 24px 2px 0;position:relative;text-align:left}.a2a_cols_container .a2a_col1{overflow-x:hidden;overflow-y:auto;-webkit-overflow-scrolling:touch}#a2a_modal input,#a2a_modal input[type=text],.a2a_menu input,.a2a_menu input[type=text]{display:block;background-image:none;box-shadow:none;line-height:100%;margin:0;outline:0;overflow:hidden;padding:0;-moz-box-shadow:none;-webkit-box-shadow:none;-webkit-appearance:none}#a2afeed_find_container input,#a2afeed_find_container input[type=text],#a2apage_find_container input,#a2apage_find_container input[type=text]{background-color:transparent;border:0;box-sizing:content-box;color:#2A2A2A;font:inherit;font-size:16px;height:28px;line-height:20px;left:38px;outline:0;margin:0;max-width:initial;min-height:initial;padding:2px 0;position:relative;width:99%}.a2a_clear{clear:both}.a2a_svg{background-repeat:no-repeat;display:block;overflow:hidden;height:32px;line-height:32px;padding:0;pointer-events:none;width:32px}.a2a_svg svg{background-repeat:no-repeat;background-position:50% 50%;border:none;display:block;left:0;margin:0 auto;overflow:hidden;padding:0;position:relative;top:0;width:auto;height:auto}a.a2a_i,i.a2a_i{display:block;float:left;border:1px solid #FFF;line-height:24px;padding:6px 8px;text-align:left;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;width:132px}a.a2a_i span,a.a2a_more span{display:inline-block;overflow:hidden;vertical-align:top}a.a2a_i .a2a_svg{margin:0 6px 0 0}a.a2a_i .a2a_svg,a.a2a_more .a2a_svg{background-size:24px;height:24px;line-height:24px;width:24px}a.a2a_sss:hover{border-left:1px solid #CCC}a.a2a_more{border-bottom:1px solid #FFF;border-left:0;border-right:0;line-height:24px;margin:6px 0 0;padding:6px;-webkit-touch-callout:none}a.a2a_more span{height:24px;margin:0 6px 0 0}.a2a_kit .a2a_svg{background-repeat:repeat}.a2a_default_style a:empty,.a2a_flex_style a:empty,.a2a_floating_style a:empty,.a2a_overlay_style a:empty{display:none}.a2a_color_buttons a,.a2a_floating_style a{text-decoration:none}.a2a_default_style:not(.a2a_flex_style) a{float:left;line-height:16px;padding:0 2px}.a2a_default_style a:hover .a2a_svg,.a2a_floating_style a:hover .a2a_svg,.a2a_overlay_style a:hover .a2a_svg svg{opacity:.7}.a2a_overlay_style.a2a_default_style a:hover .a2a_svg{opacity:1}.a2a_default_style .a2a_count,.a2a_default_style .a2a_svg,.a2a_floating_style .a2a_svg,.a2a_menu .a2a_svg,.a2a_vertical_style .a2a_count,.a2a_vertical_style .a2a_svg{border-radius:4px}.a2a_default_style .a2a_counter img,.a2a_default_style .a2a_dd,.a2a_default_style .a2a_svg{float:left}.a2a_default_style .a2a_img_text{margin-right:4px}.a2a_default_style .a2a_divider{border-left:1px solid #000;display:inline;float:left;height:16px;line-height:16px;margin:0 5px}.a2a_kit a{cursor:pointer}.a2a_floating_style{background-color:#fff;border-radius:6px;position:fixed;z-index:9999995}.a2a_overlay_style{z-index:2147483647}.a2a_floating_style,.a2a_overlay_style{animation:a2aFadeIn .2s ease-in;padding:4px}.a2a_vertical_style:not(.a2a_flex_style) a{clear:left;display:block;overflow:hidden;padding:4px}.a2a_floating_style.a2a_default_style{bottom:0}.a2a_floating_style.a2a_default_style a,.a2a_overlay_style.a2a_default_style a{padding:4px}.a2a_count{background-color:#fff;border:1px solid #ccc;box-sizing:border-box;color:#2a2a2a;display:block;float:left;font:12px Arial,Helvetica,sans-serif;height:16px;margin-left:4px;position:relative;text-align:center;width:50px}.a2a_count:after,.a2a_count:before{border:solid transparent;border-width:4px 4px 4px 0;content:"";height:0;left:0;line-height:0;margin:-4px 0 0 -4px;position:absolute;top:50%;width:0}.a2a_count:before{border-right-color:#ccc}.a2a_count:after{border-right-color:#fff;margin-left:-3px}.a2a_count span{animation:a2aFadeIn .14s ease-in}.a2a_vertical_style .a2a_counter img{display:block}.a2a_vertical_style .a2a_count{float:none;margin-left:0;margin-top:6px}.a2a_vertical_style .a2a_count:after,.a2a_vertical_style .a2a_count:before{border:solid transparent;border-width:0 4px 4px 4px;content:"";height:0;left:50%;line-height:0;margin:-4px 0 0 -4px;position:absolute;top:0;width:0}.a2a_vertical_style .a2a_count:before{border-bottom-color:#ccc}.a2a_vertical_style .a2a_count:after{border-bottom-color:#fff;margin-top:-3px}.a2a_color_buttons .a2a_count,.a2a_color_buttons .a2a_count:after,.a2a_color_buttons .a2a_count:before,.a2a_color_buttons.a2a_vertical_style .a2a_count:after,.a2a_color_buttons.a2a_vertical_style .a2a_count:before{background-color:transparent;border:none;color:#fff;float:none;width:auto}.a2a_color_buttons.a2a_vertical_style .a2a_count{margin-top:0}.a2a_flex_style{display:flex;align-items:flex-start;gap:0}.a2a_default_style.a2a_flex_style{left:0;right:0;width:100%}.a2a_vertical_style.a2a_flex_style{flex-direction:column;top:0;bottom:0}.a2a_flex_style a{display:flex;justify-content:center;flex:1;padding:4px}.a2a_flex_style.a2a_vertical_style a{flex-direction:column}.a2a_floating_style.a2a_color_buttons,.a2a_floating_style.a2a_flex_style{border-radius:0;padding:0}.a2a_floating_style.a2a_default_style.a2a_flex_style{bottom:0}.a2a_kit.a2a_flex_style .a2a_counter img,.a2a_kit.a2a_flex_style .a2a_dd,.a2a_kit.a2a_flex_style .a2a_svg{float:none}.a2a_nowrap{white-space:nowrap}.a2a_note{margin:0 auto;padding:9px;font-size:12px;text-align:center}.a2a_note .a2a_note_note{margin:0;color:#2A2A2A}.a2a_wide a{display:block;margin-top:3px;border-top:1px solid #EEE;text-align:center}.a2a_label{position:absolute!important;clip-path:polygon(0px 0px,0px 0px,0px 0px);-webkit-clip-path:polygon(0px 0px,0px 0px,0px 0px);overflow:hidden;height:1px;width:1px}.a2a_kit,.a2a_menu,.a2a_modal,.a2a_overlay{-ms-touch-action:manipulation;touch-action:manipulation;outline:0}.a2a_dd img{border:0}.a2a_button_facebook_like iframe{max-width:none}</style><script src="https://gs-cdn.optimonk.com/jfclientsdk/latest/jfclientsdk.min.js?ts=14" async=""></script><script charset="utf-8" src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/products/wspc/releasedAssets/js/mathJax-8066ca1118068b453bf4.js"></script><script type="text/javascript"></script><script charset="utf-8" src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/products/wspc/releasedAssets/js/truncate-eac30cc3a7e2e94828f1.js"></script><script charset="utf-8" src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/products/wspc/releasedAssets/js/vendors~slideshow-4b8ae6f8e81dba33e126.js"></script><script charset="utf-8" src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/products/wspc/releasedAssets/js/slideshow-54f57cfdf2e6d8c3d87d.js"></script><script charset="utf-8" src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/products/wspc/releasedAssets/js/vendors~article-9ea430f0ee6e8f6f2487.js"></script><script charset="utf-8" src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/products/wspc/releasedAssets/js/article-13348d292b9bef76a96d.js"></script><link href="https://crossmark-cdn.crossref.org/widget/v2.0/style.css" type="text/css" rel="stylesheet"><script charset="utf-8" src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/products/wspc/releasedAssets/js/requestidlecallback-polyfill-351566d1a4a10b4f802e.js"></script><script charset="utf-8" src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/products/wspc/releasedAssets/js/vendors~lazy-imports~search-aef1f54a4c8dc44b41a9.js"></script><script charset="utf-8" src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/products/wspc/releasedAssets/js/vendors~lazy-imports-db2edbb59cd19e378df0.js"></script><script charset="utf-8" src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/products/wspc/releasedAssets/js/lazy-imports-9f72124026809bf7ea8b.js"></script></head>
<body class="pb-ui">










    <div id="pb-page-content" data-ng-non-bindable="">
        <div data-pb-dropzone="main" data-pb-dropzone-name="Main">




        
        <div class="header base fixed" data-db-parent-of="sb1">



        
        <header>



        
        <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-NVG6FP');</script>
<!-- End Google Tag Manager -->




        
        













<div class="popup login-popup hidden">
    <div class="content">
        <a href="#" class="close"><i class="icon-close_thin"></i></a>
        <h2>Login to your account</h2>
        




















<div class="login-form">
    
























    <div class="social-icons">
        
        
            <a href="/action/oauth/linkedin?start=1&amp;redirectUri=%2Fworldscibooks%2F10.1142%2F10153" id="linkedInLogin" title="Use your LinkedIn credentials to sign in on this site">
                <span class="icon icon-linkedin2" aria-label="login with LinkedIn"></span>
            </a>
        
        
            <a href="/action/oauth/facebook?start=1&amp;redirectUri=%2Fworldscibooks%2F10.1142%2F10153" id="facebookLogin" title="Use your Facebook credentials to sign in on this site">
                <span class="icon icon-facebook2" aria-label="login with Facebook"></span>
            </a>
        
        
        
        
        <hr class="socialHr">
    </div>

    
    <form action="/action/doLogin" method="post"><input type="hidden" name="id" value="119162c4-9551-4055-99fe-48538e2570bc">
        





    
    
        <input type="hidden" name="redirectUri" value="/worldscibooks/10.1142/10153">
    


<input type="hidden" name="loginUri" value="/worldscibooks/10.1142/10153">
        
            <input type="hidden" name="popup" value="true">
        
        
            
            
                


























    
        
    
    
        
    
    
    
        
    

        

        
    <div class="input-group">
        <div class="label ">

            
                
                
                
                    <label for="login">Email</label>
                
            
            
        </div>
        
        
        <input id="login" class="login" type="text" name="login" value="" size="15" placeholder="">
        
                    <div class="actions">
                        
                    </div>
                
    </div>

                






















    



    
    
    <div class="input-group">
        <div class="label ">
            <label for="password">Password</label>
            
        </div>
        
        
        <input id="password" class="password" type="password" name="password" value="" autocomplete="off" placeholder="">
        <span class="password-eye-icon icon-eye hidden"></span>
        
                    <div class="actions">
                        <a href="/action/requestResetPassword" class="link show-request-reset-password">Forgot password?</a>
                    </div>
                
    </div>

            
        

        <div class="remember">
            <div class="keepMeLogin">
                <span class="label">Keep me logged in</span>
            </div>
            <div class="switch small-switch">
                
                <input id="119162c4-9551-4055-99fe-48538e2570bc-remember" class="cmn-toggle cmn-toggle-round-flat" type="checkbox" name="remember" value="true" checked="checked">
                <label class="tgl-btn" for="119162c4-9551-4055-99fe-48538e2570bc-remember"></label>
            </div>
        </div>
        
            
                <div class="submit" disabled="disabled">
                    <input class="button submit primary" type="submit" name="loginSubmit" value="Login" disabled="disabled">
                </div></form>
</div>
        <div class="login-container">
            <a href="/action/registration">
                
                <div class="center">
                    New User
                </div>
            </a>
            
                <a href="/action/ssostart?redirectUri=%2Fworldscibooks%2F10.1142%2F10153" class="float-right">
                    
                    <div class="institution-login">
                        Institutional Login
                    </div>
                </a>
            
        </div>
    </div>
</div>




        
        






<div class="popup change-password-drawer hidden">
    <div class="content">
        <a href="#" class="close cancel"><i class="icon-close_thin"></i></a>
        <div class="form">
            <h2>Change Password</h2>
            <form action="/action/changePassword" method="post"><div class="message error"></div>
                <input type="hidden" name="submit" value="submit">
                <div class="input-group">
                    <div class="label">
                        <label for="32ca9cb2-7bcf-451c-a718-7dacb5e529b9-old">Old Password</label>
                    </div>
                    <input id="32ca9cb2-7bcf-451c-a718-7dacb5e529b9-old" class="old" type="password" name="old" value="" autocomplete="off">
                    <span class="password-eye-icon icon-eye hidden"></span>
                </div>
                <div class="input-group">
                    <div class="label">
                        <label for="32ca9cb2-7bcf-451c-a718-7dacb5e529b9-new">New Password</label>
                    </div>
                    <input id="32ca9cb2-7bcf-451c-a718-7dacb5e529b9-new" class="pass-hint new" type="password" name="new" value="" autocomplete="off">
                    <span class="password-eye-icon icon-eye hidden"></span>
                    
                        







    


    


    


<div class="password-strength-indicator" data-min="8" data-max="20" data-strength="3">
    <span class="text too-short">Too Short</span>
    <span class="text weak">Weak</span>
    <span class="text medium">Medium</span>
    <span class="text strong">Strong</span>
    <span class="text very-strong">Very Strong</span>
    <span class="text too-long">Too Long</span>
</div>
                    
                </div>
                <input class="button primary submit" type="submit" value="Submit" disabled="disabled"></form>
        </div>
        <div class="success-template hidden">
            <h2>Password Changed Successfully</h2>
            <p>Your password has been changed</p>
        </div>
    </div>
</div>





        
        





<div class="popup registration-popup hidden">
    <div class="content">
        <a href="#" class="close"><i class="icon-close_thin"></i></a>
        <h2>Create a new account</h2>
        <form action="/action/registration" class="registration-form" method="post"><input type="hidden" name="redirectUri" value="/worldscibooks/10.1142/10153">
            <div class="input-group">
                <div class="label">
                    <label for="4e824763-0b45-4b53-bcb3-79723a798efa.email">Email</label>
                </div>
                <input id="4e824763-0b45-4b53-bcb3-79723a798efa.email" class="email" type="email" name="email" value="">
            </div>
            <div class="submit">
                <input class="button submit primary" type="submit" value="Register" disabled="disabled">
            </div></form>
        <div class="center">
            <a href="/action/showLogin" class="show-login">
                
                Returning user
            </a>
        </div>
    </div>
</div>




        
        



<div class="popup top-drawer request-reset-password-drawer hidden">
    <div class="content">
        <div class="form">
            





<p>Can't sign in? Forgot your password?</p>
<p class="sub">Enter your email address below and we will send you the reset instructions</p>
<div class="message error"></div>
<form action="/action/requestResetPassword" class="request-reset-password-form" method="post"><input type="hidden" name="requestResetPassword" value="true">
    
    <div class="input-group">
        <div class="label">
            <label for="d08ba088-273c-4e80-a5d6-e71647cef18b.email">Email</label>
        </div>
        <input id="d08ba088-273c-4e80-a5d6-e71647cef18b.email" class="email" type="text" name="email" value="" size="15">
    </div>
    
        
            <div class="password-recaptcha-ajax"></div>
        
        
    
    
    <div class="password-reset__check-email">Please check your inbox for the reset password link that is only valid for 24 hours.</div>
    <input class="button primary submit" type="submit" name="submit" value="Submit" disabled="disabled"></form>
            
            <div class="center">
                <a href="#" class="cancel">Cancel</a>
            </div>
        </div>
        <div class="success-template hidden">
            <p>If the address matches an existing account you will receive an email with instructions to reset your password</p>
            <div class="center">
                <a href="#" class="cancel">Close</a>
            </div>
        </div>
    </div>
</div>




        
        




<div class="popup top-drawer request-username-drawer username-popup hidden">
    <div class="content">
        <a href="#" class="close"><i class="icon-close_thin"></i></a>
        <h2>Request Username</h2>
        <div class="form">
            <p>Can't sign in? Forgot your username?</p>
            <p class="sub">Enter your email address below and we will send you your username</p>
            <div class="message error"></div>
            <form action="/action/requestUsername" method="post"><input type="hidden" name="requestUsername" value="requestUsername">
                <div class="input-group">
                    <div class="label">
                        <label for="2b3925a2-1b57-45ab-a1cc-e6eb17123bf9.email">Email</label>
                    </div>
                    <input id="2b3925a2-1b57-45ab-a1cc-e6eb17123bf9.email" class="email" type="text" name="email" value="" size="15">
                </div>
                
                    <div class="username-recaptcha-ajax"></div>
                
                <input class="button primary submit" type="submit" name="submit" value="Submit" disabled="disabled">
                <div class="center">
                    <a href="#" class="cancel">Close</a>
                </div></form>
        </div>
        <div class="success-template hidden note">
            <p>If the address matches an existing account you will receive an email with instructions to retrieve your username</p>
        </div>
    </div>
</div>




        
        










    
    
        <div data-widget-def="ux3-layout-widget" data-widget-id="f3992bda-f515-41a7-a6c2-85c77bd2ff4b" class="container header--first-row">
        



        
        <div class="pull-left">



        
        <a href="/" title="World Scientific"><img id="" alt="World Scientific" src="/pb-assets/releasedAssets/images/WSPC-LOGO-250.png"></a>
</div><div class="pull-right">









    
    
        <div data-widget-def="UX3InstitutionBanner" data-widget-id="ecf8e463-cbfd-489b-adc6-13df5e640f04" class="institution-wrapper">
        



        
        <div class="institution"><img src="/userimages/ed1b706d-e153-474e-a42e-396816d3e45c/banner-17ffacd162b?trick=1685497323699" alt="HONG KONG METROPOLITAN UNIVERSITY" class="institution__image"><div class="institution-info-wrapper"><span class="institution__intro">brought to you by</span><span class="institution__name">HONG KONG METROPOLITAN UNIVERSITY</span></div></div>

        </div>
    





        
        <div class="header__quick-menu">



        
        <ul class="rlist--inline"><li>



        
        <a href="#" title="Search" data-db-target-for="sb1" class="quick-menu__item"><i aria-hidden="true" class="block-icon icon-search"></i><span>Search</span></a><div data-db-target-of="sb1" class="dropBlock__holder quick-search__dropBlock quickSearchFormContainer"><div class="container"><div class="quick-search"><div class="row clearfix tab"><div class="col-md-2"><div class="dropBlock" data-db-parent-of="dbTab-0"><a href="#" class="dropBlock__link" data-db-target-for="dbTab-0"><span>This Book</span><i class="icon-arrow_d_n" aria-hidden="true"></i></a><ul role="tablist" class="rlist tab__nav dropblock--tab" data-db-target-of="dbTab-0"><li role="presentation" class="tab__nav__item active"><a href="#pane-374c2551-8302-4bf6-989c-6e4d27b968c20" aria-controls="#pane-0" role="tab" data-toggle="tab" title="This Book" id="pane-374c2551-8302-4bf6-989c-6e4d27b968c20-con" class="tab__nav__item__link" tabindex="0" aria-selected="true">This Book</a></li><li role="presentation" class="tab__nav__item"><a href="#pane-374c2551-8302-4bf6-989c-6e4d27b968c21" aria-controls="#pane-1" role="tab" data-toggle="tab" title="Anywhere" id="pane-374c2551-8302-4bf6-989c-6e4d27b968c21-con" class="tab__nav__item__link" tabindex="-1" aria-selected="false">Anywhere</a></li></ul></div></div><div class="gutterless col-md-8"><div class="tab__content quick-search__searchbox__content"><div id="pane-374c2551-8302-4bf6-989c-6e4d27b968c20" aria-labelledby="pane-374c2551-8302-4bf6-989c-6e4d27b968c20-con" role="tabpanel" class="tab__pane quick-search-pane quick-search-pane__book active" aria-hidden="false"><form action="/action/doSearch" name="thisBookQuickSearch" method="get"><fieldset><legend class="sr-only">Quick Search in Books</legend><div class="input-group option-0 "><label for="AllField374c2551-8302-4bf6-989c-6e4d27b968c20" class="sr-only">Enter words / phrases / DOI / ISBN / keywords / authors / etc</label><div class="autoComplete_wrapper" role="combobox" aria-owns="autoComplete_list_1" aria-haspopup="true" aria-expanded="false"><input type="search" autocomplete="off" id="AllField374c2551-8302-4bf6-989c-6e4d27b968c20" name="AllField" placeholder="Enter words / phrases / DOI / ISBN / keywords / authors / etc" data-auto-complete-max-words="7" data-auto-complete-max-chars="32" data-contributors-conf="3" data-topics-conf="3" data-publication-titles-conf="3" data-history-items-conf="3" value="" class="auto-complete" aria-controls="autoComplete_list_1" aria-autocomplete="both"></div><input type="hidden" name="ContentGroupKey" value="10.1142/10153"></div><ul id="autoComplete_list_1" role="listbox" hidden="" class="autoComplete rlist"></ul><button type="submit" title="Search" class="btn quick-search__button icon-search"><span class="sr-only">Search</span><span>Search</span></button><div class="quick-search__checkbox-container"><div class="quick-search__checkbox-container__wrapper"><span class="mb-0 mr-3">Access type:</span><label class="align-items-center mb-0 mr-3 checkbox--primary"><input type="checkbox" name="access" value="user"><span class="label-txt">Only show content I have full access to</span></label><label class="align-items-center mb-0 mr-3 checkbox--primary"><input type="checkbox" name="access" value="18"><span class="label-txt">Only show Open Access</span></label></div></div></fieldset></form></div><div id="pane-374c2551-8302-4bf6-989c-6e4d27b968c21" aria-labelledby="pane-374c2551-8302-4bf6-989c-6e4d27b968c21-con" role="tabpanel" class="tab__pane quick-search-pane quick-search-pane__anywhere" aria-hidden="true"><form action="/action/doSearch" name="defaultQuickSearch" method="get"><fieldset><legend class="sr-only">Quick Search anywhere</legend><div class="input-group option-1 "><label for="AllField374c2551-8302-4bf6-989c-6e4d27b968c21" class="sr-only">Enter words / phrases / DOI / ISBN / keywords / authors / etc</label><div class="autoComplete_wrapper" role="combobox" aria-owns="autoComplete_list_2" aria-haspopup="true" aria-expanded="false"><input type="search" autocomplete="off" id="AllField374c2551-8302-4bf6-989c-6e4d27b968c21" name="AllField" placeholder="Enter words / phrases / DOI / ISBN / keywords / authors / etc" data-auto-complete-max-words="7" data-auto-complete-max-chars="32" data-contributors-conf="3" data-topics-conf="3" data-publication-titles-conf="3" data-history-items-conf="3" value="" class="auto-complete" aria-controls="autoComplete_list_2" aria-autocomplete="both"></div></div><ul id="autoComplete_list_2" role="listbox" hidden="" class="autoComplete rlist"></ul><button type="submit" title="Search" class="btn quick-search__button icon-search"><span class="sr-only">Search</span><span>Search</span></button><div class="quick-search__checkbox-container"><div class="quick-search__checkbox-container__wrapper"><span class="mb-0 mr-3">Access type:</span><label class="align-items-center mb-0 mr-3 checkbox--primary"><input type="checkbox" name="access" value="user"><span class="label-txt">Only show content I have full access to</span></label><label class="align-items-center mb-0 mr-3 checkbox--primary"><input type="checkbox" name="access" value="18"><span class="label-txt">Only show Open Access</span></label></div></div></fieldset></form></div></div></div><div class="col-md-2">



        
        <a href="/search/advanced" class="pull-right quick-search-advanced-link">Advanced Search</a>
</div></div></div></div></div>
</li><li>









    
    
        <div data-widget-def="eCommerceCartIndicatorWidget" data-widget-id="919a768a-3ccb-4a54-a5fb-9ec266ca3a9c" class="eCommerceCartIndicatorWidget">
        



        
        















<div class="eCommerceCartIndicatorWidget">
    
        
        
            <a href="/action/showCart?FlowID=1" id="cartLabel" title="Show shopping cart">
                <div class="cartLabel">
                    <span class="icon-shoppingcart"></span>
                    <span class="filter-count filter-count-bubble shopping-cart hidden" data-id="cart-size">0</span>
                        
                    <span class="cartText">My Cart</span>
                </div>
            </a>
        
    
</div>

        </div>
    

</li><li>









    
    
        <div data-widget-def="literatumNavigationLoginBar" data-widget-id="afb30c65-16c7-48c2-a29d-0490ff094f7a" class="right-side">
        



        
        




    








    
    
        




    







<div class="loginBar login-open">
    <a href="/action/showLogin?uri=%2Fworldscibooks%2F10.1142%2F10153" class="show-login show-login-customization">
        <span class="icon-profile_empty" title="Register/Sign In"></span>
        <span class="sign-in-label">Sign in</span>
    </a>
</div>



    



        </div>
    

</li></ul>
</div>
</div>

        </div>
    





        
        <a href="#afterNav-w5v" class="sr-only-focusable">Skip main navigation</a><div class="main-nav"><a href="#main-menu" data-target="main-menu" data-toggle="nav" class="main-nav__toggle__controller"><i class="icon-menu2"><span class="sr-only">Close Drawer Menu</span></i><i class="icon-close_thin"><span class="sr-only">Open Drawer Menu</span></i></a><nav role="navigation" id="main-menu" data-ctrl-res="screen-sm" aria-label="Main Navigation" class="drawer__nav container gutterless hidden-sm hidden-xs"><a href="#" data-redirect-to="/" class="menu-header hidden-md hidden-lg">Home</a><ul id="menubar" role="menubar" class="menubar rlist--inline"><li role="menuitem" aria-haspopup="true" aria-label="Subject" id="menu-item-main-menu-0" class="dropdown menu-parent"><a href="/action/showPublications?PubType=all" id="main-menu-1" data-toggle="dropdown" class="dropdown__toggle"><span>Subject</span><i aria-hidden="true" class="icon-arrow_r pull-right hidden-md hidden-lg"></i><i aria-hidden="true" class="icon-section_arrow_d pull-right hidden-sm hidden-xs"></i></a><ul aria-labelledby="main-menu-1" role="menu" class="rlist dropdown__menu"><li role="menuitem" tabindex="-1" aria-label="All Subjects" class="menu-item"><a href="/action/showPublications" target="_blank"><span>All Subjects</span>&nbsp;<i aria-hidden="true" class="icon-download-sitation"></i></a></li><li role="menuitem" tabindex="-1" aria-label="Asian Studies" class="menu-item"><a href="/page/asianstudies"><span>Asian Studies</span></a></li><li role="menuitem" tabindex="-1" aria-label="Business &amp; Management" class="menu-item"><a href="/page/business"><span>Business &amp; Management</span></a></li><li role="menuitem" tabindex="-1" aria-label="Chemistry" class="menu-item"><a href="/page/chemistry"><span>Chemistry</span></a></li><li role="menuitem" tabindex="-1" aria-label="Children’s Books" class="menu-item"><a href="https://worldscientificedu.com"><span>Children’s Books</span></a></li><li role="menuitem" tabindex="-1" aria-label="Computer Science" class="menu-item"><a href="/page/compsci"><span>Computer Science</span></a></li><li role="menuitem" tabindex="-1" aria-label="Economics &amp; Finance" class="menu-item"><a href="/page/economics"><span>Economics &amp; Finance</span></a></li><li role="menuitem" tabindex="-1" aria-label="Education" class="menu-item"><a href="/page/education"><span>Education</span></a></li><li role="menuitem" tabindex="-1" aria-label="Engineering / Acoustics" class="menu-item"><a href="/page/engineering"><span>Engineering / Acoustics</span></a></li><li role="menuitem" tabindex="-1" aria-label="Environmental Science" class="menu-item"><a href="/page/environsci"><span>Environmental Science</span></a></li><li role="menuitem" tabindex="-1" aria-label="Life Sciences / Biology" class="menu-item"><a href="/page/lifesci"><span>Life Sciences / Biology</span></a></li><li role="menuitem" tabindex="-1" aria-label="Materials Science" class="menu-item"><a href="/page/materialsci"><span>Materials Science</span></a></li><li role="menuitem" tabindex="-1" aria-label="Mathematics" class="menu-item"><a href="/page/mathematics"><span>Mathematics</span></a></li><li role="menuitem" tabindex="-1" aria-label="Medicine" class="menu-item"><a href="/page/medsci"><span>Medicine</span></a></li><li role="menuitem" tabindex="-1" aria-label="Nanotechnology &amp; Nanoscience" class="menu-item"><a href="/page/nanosci"><span>Nanotechnology &amp; Nanoscience</span></a></li><li role="menuitem" tabindex="-1" aria-label="Nonlinear Science, Chaos &amp; Dynamical Systems" class="menu-item"><a href="/page/nonlinearsci"><span>Nonlinear Science, Chaos &amp; Dynamical Systems</span></a></li><li role="menuitem" tabindex="-1" aria-label="Physics &amp; Astronomy" class="menu-item"><a href="/page/physics"><span>Physics &amp; Astronomy</span></a></li><li role="menuitem" tabindex="-1" aria-label="Popular &amp; General Science" class="menu-item"><a href="/page/generalinterest"><span>Popular &amp; General Science</span></a></li><li role="menuitem" tabindex="-1" aria-label="Social Sciences" class="menu-item"><a href="/page/socialsci"><span>Social Sciences</span></a></li><li role="menuitem" tabindex="-1" aria-label="&amp;#x534E;&amp;#x6587;&amp;#x4E66;&amp;#x7C4D; (Chinese Titles)" class="menu-item"><a href="/topic/mktcode-gc000?startPage=&amp;target=bookTitleSearch&amp;content=bookTitle&amp;sortBy=Earliest"><span>华文书籍 (Chinese Titles)</span></a></li></ul></li><li role="menuitem" aria-label="Journals" id="menu-item-main-menu-1" class="menu-item"><a href="/page/wsjournals"><span>Journals</span></a></li><li role="menuitem" aria-label="Books" id="menu-item-main-menu-2" class="menu-item"><a href="/page/worldscibooks"><span>Books</span></a></li><li role="menuitem" aria-label="Major Reference Works" id="menu-item-main-menu-3" class="menu-item"><a href="/page/major-reference-works"><span>Major Reference Works</span></a></li><li role="menuitem" aria-haspopup="true" aria-label="Resources for Partners" id="menu-item-main-menu-4" class="dropdown menu-parent"><a href="#" id="main-menu-2" data-toggle="dropdown" class="dropdown__toggle"><span>Resources for Partners</span><i aria-hidden="true" class="icon-arrow_r pull-right hidden-md hidden-lg"></i><i aria-hidden="true" class="icon-section_arrow_d pull-right hidden-sm hidden-xs"></i></a><ul aria-labelledby="main-menu-2" role="menu" class="rlist dropdown__menu"><li role="menuitem" tabindex="-1" aria-label="Publish with us" class="menu-item"><a href="/page/publish-with-us"><span>Publish with us</span></a></li><li role="menuitem" tabindex="-1" aria-label="For Authors" class="menu-item"><a href="/page/authors/index"><span>For Authors</span></a></li><li role="menuitem" tabindex="-1" aria-label="For Booksellers" class="menu-item"><a href="/page/booksellers"><span>For Booksellers</span></a></li><li role="menuitem" tabindex="-1" aria-label="For Librarians" class="menu-item"><a href="/page/librarians"><span>For Librarians</span></a></li><li role="menuitem" tabindex="-1" aria-label="For Societies" class="menu-item"><a href="/page/societies"><span>For Societies</span></a></li><li role="menuitem" tabindex="-1" aria-label="For Individual Customers" class="menu-item"><a href="/page/help/how-to-order"><span>For Individual Customers</span></a></li><li role="menuitem" tabindex="-1" aria-label="Copyright &amp; Permissions" class="menu-item"><a href="/page/permissions"><span>Copyright &amp; Permissions</span></a></li><li role="menuitem" tabindex="-1" aria-label="Translation Rights" class="menu-item"><a href="/page/translation-rights"><span>Translation Rights</span></a></li></ul></li><li role="menuitem" aria-label="Open Access" id="menu-item-main-menu-5" class="menu-item"><a href="/page/open"><span>Open Access</span></a></li><li role="menuitem" aria-haspopup="true" aria-label="About Us" id="menu-item-main-menu-6" class="dropdown menu-parent"><a href="#" id="main-menu-3" data-toggle="dropdown" class="dropdown__toggle"><span>About Us</span><i aria-hidden="true" class="icon-arrow_r pull-right hidden-md hidden-lg"></i><i aria-hidden="true" class="icon-section_arrow_d pull-right hidden-sm hidden-xs"></i></a><ul aria-labelledby="main-menu-3" role="menu" class="rlist dropdown__menu"><li role="menuitem" tabindex="-1" aria-label="About Us" class="menu-item"><a href="/page/about/corporate-profile"><span>About Us</span></a></li><li role="menuitem" tabindex="-1" aria-label="News" class="menu-item"><a href="/action/showNews"><span>News</span></a></li><li role="menuitem" tabindex="-1" aria-label="Press Releases" class="menu-item"><a href="/page/pressroom"><span>Press Releases</span></a></li><li role="menuitem" tabindex="-1" aria-label="Contact Us" class="menu-item"><a href="/page/contactus"><span>Contact Us</span></a></li><li role="menuitem" tabindex="-1" aria-label="Privacy Policy" class="menu-item"><a href="/page/help/privacy-policy"><span>Privacy Policy</span></a></li><li role="menuitem" tabindex="-1" aria-label="Sitemap" class="menu-item"><a href="/page/sitemap"><span>Sitemap</span></a></li></ul></li><li role="menuitem" aria-haspopup="true" aria-label="Help" id="menu-item-main-menu-7" class="dropdown menu-parent"><a href="#" id="main-menu-4" data-toggle="dropdown" class="dropdown__toggle"><span>Help</span><i aria-hidden="true" class="icon-arrow_r pull-right hidden-md hidden-lg"></i><i aria-hidden="true" class="icon-section_arrow_d pull-right hidden-sm hidden-xs"></i></a><ul aria-labelledby="main-menu-4" role="menu" class="rlist dropdown__menu"><li role="menuitem" tabindex="-1" aria-label="Help" class="menu-item"><a href="/page/help"><span>Help</span></a></li><li role="menuitem" tabindex="-1" aria-label="How to Order" class="menu-item"><a href="/page/help/how-to-order"><span>How to Order</span></a></li></ul></li></ul></nav><span id="afterNav-w5v" tabindex="-1"></span></div><div class="header__dropzone">



        
        <div class="cookiePolicy-popup"><div class="container"><span class="cookiePolicy-popup__content"><div id="cookieBanner" class="cookieBanner">
    <h4 class="b-header">Cookies Notification</h4>
    <div class="b-body" style="padding-bottom: 5px;">
      We use cookies on this site to enhance your user experience. By continuing to browse the site, you consent to the use of our cookies.
        <u><a href="/page/help/privacy-policy">Learn More</a></u>
    <input id="accept-cookie-policy" type="button" value="I Agree">
    </div>
</div></span><a href="#" aria-label="Agree to cookie policy and close message" class="cookiePolicy-popup__close close">×</a></div></div>




        
        <style>
#checkadblockernow {
display: none;
padding: 20px 10px;
background: #2f4f4f;
text-align: center;
font-weight: bold;
color: #ffffff;
border-bottom: 1px solid #b8b8b8;
}
</style>
<div id="checkadblockernow">
  Our website is made possible by displaying certain online content using javascript.<br>
  In order to view the full content, please <a href="/help/adblocker-whitelist" style="color:#ffffff;"><u>disable</u></a> your ad blocker or <a href="/help/adblocker-whitelist" style="color:#ffffff;"><u>whitelist</u></a> our website www.worldscientific.com.
</div>

<script src="/pb-assets/wspc-site/js/ads-1685353094560.js" type="text/javascript"></script>
<script type="text/javascript">

if(!document.getElementById('banner_ad')){
  document.getElementById('checkadblockernow').style.display='block';
}
else{console.log("in");}
</script>










    
    
        <div data-widget-def="literatumAd" data-widget-id="972df656-2d8b-480a-80df-1f295fbc07d1" class="article-adv grid-sm-2 home-sections bottom-margin">
        



        
        



    
        <div class="pb-ad">
            <table width="100%" bgcolor="#EDF4FA" collspacing="0">
 <tbody><tr>
  <td>
  <center><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/sda/1488/summersale2023.png"></center>
  </td>
 </tr>
</tbody></table>


            
        </div>
    

    

    



        </div>
    





        
        



    

    

    
        
    


</div>
</header>




        
        <style>
#maintenancemsg {
padding: 10px 10px;
background: #d6ecf9;
text-align: center;
color: #000000;
display: none;
border-top: 1px solid #b8b8b8;
border-bottom: 1px solid #b8b8b8;
}
</style>
<div id="maintenancemsg">
<h3><font color="red">System Upgrade on Tue, Oct 25th, 2022 at 2am (EDT)</font></h3>
Existing users will be able to log into the site and access content. However, E-commerce and registration of new users may not be available for up to 12 hours.
<br>
For online purchase, please visit us again. Contact us at <a href="mailto:customercare@wspc.com">customercare@wspc.com</a> for any enquiries.
</div>

</div>




        
        <main class="content book-home" style="min-height: 231.2px;">



        
        <div class="top-image"></div><div class="container"><div class="card card--shadow card--gutter meta__body journal-banner book-banner"><div class="meta__left-side left-side-image"><div class="image-container"><img src="/na101/home/literatum/publisher/wspc/books/content/books/2017/10153/10153/20160928-01/10153.cover.jpg" alt="Pattern Recognition and Big Data cover"></div><div class="banner__meta"><h1 class="meta__title">Pattern Recognition and Big Data</h1><div class="meta__info"><div class="meta__section"><span class="doi"><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/10153" class="primary-link-color">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/10153</a></span><span>&nbsp;|&nbsp;</span><span class="cover-date">February 2017</span></div><span class="pagecount">Pages: 876</span><ul class="rlist--inline loa mobile-authors" title="list of authors"><li>Edited By:&nbsp;</li><li><span class="hlFld-ContribAuthor"><a href="/author/Pal%2C+Amita" title="Amita Pal">Amita Pal</a> (<i>Indian Statistical Institute, India</i>)</span><span class="author-separator">&nbsp;and&nbsp;</span></li><li><span class="hlFld-ContribAuthor"><a href="/author/Pal%2C+Sankar+K" title="Sankar K Pal">Sankar K Pal</a> (<i>Indian Statistical Institute, India</i>)</span></li></ul><div class="article-tools-wrapper"><div class="meta__section book-links"><i aria-hidden="true" class="icon-document"></i><span class="coolBar__section book-download"><a href="/doi/reader/10.1142/10153"><span>View Full Book</span></a></span></div>









    
    
        <div data-widget-def="gql-article-tools" data-widget-id="233e22d8-a327-471b-bf54-3179d2740fc8" class="coolBar__section coolBar-tools">
        



        
        <a data-db-target-for="233e22d8-a327-471b-bf54-3179d2740fc8" data-db-switch="icon-close_thin" aria-haspopup="true" aria-controls="233e22d8-a327-471b-bf54-3179d2740fc8_Pop" role="button" id="233e22d8-a327-471b-bf54-3179d2740fc8_Ctrl" data-slide-target="#233e22d8-a327-471b-bf54-3179d2740fc8_Pop" aria-label="article tools" class="article-tools__ctrl w-slide__btn" tabindex="0"><i aria-hidden="true" class="icon-Icon_Tools"></i><span>Tools</span></a><div data-db-target-of="233e22d8-a327-471b-bf54-3179d2740fc8" aria-labelledby="233e22d8-a327-471b-bf54-3179d2740fc8_Ctrl" id="233e22d8-a327-471b-bf54-3179d2740fc8_Pop" class="article-tools__block fixed dropBlock__holder"><ul role="menu" class="rlist w-slide--list"><li role="presentation" class="article-tool"><a href="/personalize/addFavoritePublication?doi=10.1142%2F10153" role="menuitem"><i aria-hidden="true" class="icon-Icon_Star-26"></i><span>Add to favorites</span></a></li><li role="presentation" class="article-tool"><a href="/action/showCitFormats?doi=10.1142%2F10153" role="menuitem"><i aria-hidden="true" class="icon-Icon_Download"></i><span>Download Citations</span></a></li><li role="presentation" class="article-tool"><a href="/action/addCitationAlert?doi=10.1142%2F10153" role="menuitem"><i aria-hidden="true" class="icon-Icon_Track-citations"></i><span>Track Citations</span></a></li><li role="presentation" class="article-tool"><a href="/action/recommendation?doi=10.1142%2F10153" role="menuitem"><i aria-hidden="true" class="icon-Icon_mail"></i><span>Recommend to Library</span></a></li></ul></div>

        </div>
    












    
    
        <div data-widget-def="UX3share" data-widget-id="041a240d-a7fa-4878-8436-0b5e87a806b3" class="coolBar__section coolBar-share">
        



        
        <!-- Go to https://www.addtoany.com/buttons/customize/ to customize your tools --><script type="text/javascript" defer="defer" src="https://static.addtoany.com/menu/page.js"></script><a href="#" data-db-target-for="041a240d-a7fa-4878-8436-0b5e87a806b3" data-db-switch="icon-close_thin" data-slide-target="#041a240d-a7fa-4878-8436-0b5e87a806b3_Pop" aria-labelledby="share-label" class="share__ctrl w-slide__btn"><i aria-hidden="true" class="icon-Icon_Share"></i><span id="share-label">Share</span></a><div data-db-target-of="041a240d-a7fa-4878-8436-0b5e87a806b3" id="041a240d-a7fa-4878-8436-0b5e87a806b3_Pop" class="share__block dropBlock__holder fixed"><div class="pb-dropzone" data-pb-dropzone="shareBlock" title="shareBlock"></div><span class="sr-only">Share on</span><ul class="rlist w-slide--list a2a a2a_kit a2a_kit_size_32 a2a_default_style" style="line-height: 32px;"><li><a role="link" title="Facebook" class="a2a_button_facebook" target="_blank" rel="nofollow noopener" href="/#facebook"><span class="a2a_svg a2a_s__default a2a_s_facebook a2a_img_text" style="background-color: rgb(24, 119, 242);"><svg focusable="false" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path fill="#FFF" d="M17.78 27.5V17.008h3.522l.527-4.09h-4.05v-2.61c0-1.182.33-1.99 2.023-1.99h2.166V4.66c-.375-.05-1.66-.16-3.155-.16-3.123 0-5.26 1.905-5.26 5.405v3.016h-3.53v4.09h3.53V27.5h4.223z"></path></svg></span>Facebook</a></li><li><a role="link" title="Twitter" class="a2a_button_twitter" target="_blank" rel="nofollow noopener" href="/#twitter"><span class="a2a_svg a2a_s__default a2a_s_twitter a2a_img_text" style="background-color: rgb(29, 155, 240);"><svg focusable="false" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path fill="#FFF" d="M28 8.557a9.913 9.913 0 0 1-2.828.775 4.93 4.93 0 0 0 2.166-2.725 9.738 9.738 0 0 1-3.13 1.194 4.92 4.92 0 0 0-3.593-1.55 4.924 4.924 0 0 0-4.794 6.049c-4.09-.21-7.72-2.17-10.15-5.15a4.942 4.942 0 0 0-.665 2.477c0 1.71.87 3.214 2.19 4.1a4.968 4.968 0 0 1-2.23-.616v.06c0 2.39 1.7 4.38 3.952 4.83-.414.115-.85.174-1.297.174-.318 0-.626-.03-.928-.086a4.935 4.935 0 0 0 4.6 3.42 9.893 9.893 0 0 1-6.114 2.107c-.398 0-.79-.023-1.175-.068a13.953 13.953 0 0 0 7.55 2.213c9.056 0 14.01-7.507 14.01-14.013 0-.213-.005-.426-.015-.637.96-.695 1.795-1.56 2.455-2.55z"></path></svg></span>Twitter</a></li><li><a role="link" title="Linked In" class="a2a_button_linkedin" target="_blank" rel="nofollow noopener" href="/#linkedin"><span class="a2a_svg a2a_s__default a2a_s_linkedin a2a_img_text" style="background-color: rgb(0, 123, 181);"><svg focusable="false" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M6.227 12.61h4.19v13.48h-4.19V12.61zm2.095-6.7a2.43 2.43 0 0 1 0 4.86c-1.344 0-2.428-1.09-2.428-2.43s1.084-2.43 2.428-2.43m4.72 6.7h4.02v1.84h.058c.56-1.058 1.927-2.176 3.965-2.176 4.238 0 5.02 2.792 5.02 6.42v7.395h-4.183v-6.56c0-1.564-.03-3.574-2.178-3.574-2.18 0-2.514 1.7-2.514 3.46v6.668h-4.187V12.61z" fill="#FFF"></path></svg></span>Linked In</a></li><li><a role="link" title="Reddit" class="a2a_button_reddit" target="_blank" rel="nofollow noopener" href="/#reddit"><span class="a2a_svg a2a_s__default a2a_s_reddit a2a_img_text" style="background-color: rgb(255, 69, 0);"><svg focusable="false" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M28.543 15.774a2.953 2.953 0 0 0-2.951-2.949 2.882 2.882 0 0 0-1.9.713 14.075 14.075 0 0 0-6.85-2.044l1.38-4.349 3.768.884a2.452 2.452 0 1 0 .24-1.176l-4.274-1a.6.6 0 0 0-.709.4l-1.659 5.224a14.314 14.314 0 0 0-7.316 2.029 2.908 2.908 0 0 0-1.872-.681 2.942 2.942 0 0 0-1.618 5.4 5.109 5.109 0 0 0-.062.765c0 4.158 5.037 7.541 11.229 7.541s11.22-3.383 11.22-7.541a5.2 5.2 0 0 0-.053-.706 2.963 2.963 0 0 0 1.427-2.51zm-18.008 1.88a1.753 1.753 0 0 1 1.73-1.74 1.73 1.73 0 0 1 1.709 1.74 1.709 1.709 0 0 1-1.709 1.711 1.733 1.733 0 0 1-1.73-1.711zm9.565 4.968a5.573 5.573 0 0 1-4.081 1.272h-.032a5.576 5.576 0 0 1-4.087-1.272.6.6 0 0 1 .844-.854 4.5 4.5 0 0 0 3.238.927h.032a4.5 4.5 0 0 0 3.237-.927.6.6 0 1 1 .844.854zm-.331-3.256a1.726 1.726 0 1 1 1.709-1.712 1.717 1.717 0 0 1-1.712 1.712z" fill="#fff"></path></svg></span>Reddit</a></li><li><a role="link" title="Email" class="a2a_button_email" target="_blank" rel="nofollow noopener" href="/#email"><span class="a2a_svg a2a_s__default a2a_s_email a2a_img_text" style="background-color: rgb(1, 102, 255);"><svg focusable="false" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path fill="#FFF" d="M26 21.25v-9s-9.1 6.35-9.984 6.68C15.144 18.616 6 12.25 6 12.25v9c0 1.25.266 1.5 1.5 1.5h17c1.266 0 1.5-.22 1.5-1.5zm-.015-10.765c0-.91-.265-1.235-1.485-1.235h-17c-1.255 0-1.5.39-1.5 1.3l.015.14s9.035 6.22 10 6.56c1.02-.395 9.985-6.7 9.985-6.7l-.015-.065z"></path></svg></span>Email</a></li><div style="clear: both;"></div></ul></div>

        </div>
    

</div><div class="meta__dropzone__html"></div>









    
    
        <div data-widget-def="ux3-layout-widget" data-widget-id="7de0e474-1b01-4201-b3f8-ea60d65a73ea">
        



        
        <div class="coolBar__section coolBar-tools"></div><div class="coolBar__section coolBar-share"></div><div class="coolBar__section coolBar-share">



        
        <script>
    var urlraw = window.location.toString().split("?");
    var urlfirst = urlraw[0].split("#");
    var url = urlfirst[0].split("/");
    var ids="";
    if(url[4] == "10.1142"){ids = url[5];}else{ids = url[6];}
    if(screen.width <= 414)
    {
      document.write('<a style="margin: 0 0 0 15px;" href="/action/recommendation?doi=10.1142%2F'+ids+'"><i class="icon-Icon_mail"></i><span> Recommend to Library</span></a>');
    }
    else
    {
      document.write('<a class="share__ctrl w-slide__btn" style="margin: 0 0 0 15px;" href="/action/recommendation?doi=10.1142%2F'+ids+'"><i class="icon-Icon_mail"></i><span>Recommend to Library</span></a>');
    }
    </script><a class="share__ctrl w-slide__btn" style="margin: 0 0 0 15px;" href="/action/recommendation?doi=10.1142%2F10153"><i class="icon-Icon_mail"></i><span>Recommend to Library</span></a>
</div>

        </div>
    





        
        <div class="grid-sm-2">



        
        <script src="/pb-assets/wspc-site/childrenbookpeekinside/childrenbookpeekinside-1684813342580.js"></script>
<div id="childrenbookdisplay"></div>
<script>
var urlraw = window.location.toString().split("?");
var urlfirst = urlraw[0].split("#");
var url = urlfirst[0].split("/");
var ids="";
if(url[4] == "10.1142"){ids = url[5];}else{ids = url[6];}
var finalid = ids;
if(!childpilist[finalid]){document.getElementById("childrenbookdisplay").innerHTML = "";}
else if(childpilist[finalid] != ""){document.getElementById("childrenbookdisplay").innerHTML = childpilist[finalid];}
</script>
<style>
#peekinsidebtn
{
  background-color:#ffd700;
  width:200px;
  font-size:15px;
  color:#192b6c;
  border-radius:5px;
}
#peekinsidebtn:hover
{
  color:#000000;
}
@media only screen and (max-width: 532px) {
  #peekinsidebtn
  {
    margin: 20px 0 0 0;
  }
}
</style>

</div>
</div></div></div><div class="meta__right-side">









    
    
        <div data-widget-def="literatumAd" data-widget-id="18c01e4e-79d1-4d85-a80d-44501be3f11e" class="article-adv">
        



        
        



    

    

    
        
    



        </div>
    





        
        



    

    

    
        
    






        
        <div class="do-nyp"></div>










    
    
        <div data-widget-def="eCommercePurchaseAccessWidget" data-widget-id="7cd848bc-0161-4445-9d0c-3741a9c4539b" class="eCommercePurchaseAccessWidget">
        



        
        











    <div class="eCommercePurchaseAccessWidgetContainer ">
        <a data-bind="expandSection" class="purchaseAreaList_expand active" href="#purchasePanel" id="purchaseLink">Purchase</a>
        
            
                
                <a data-bind="saveItem" data-doi="10.1142/10153" class="save-for-later-link" href="/action/saveItem?doi=10.1142/10153">
                    Save for later
                </a>
                
                <a class="saved-go-cart hidden" href="/action/showCart?FlowID=2"><span class="icon-cart-icon-material"></span> Item saved, go to cart </a>
            
            
        
        <div class="purchaseAreaList_expanded" id="#purchasePanel">
            











<div class="purchase-options-container">
    

    
        <div class="savedItem-info hidden">
            <p></p>
        </div>
    

    
        
            
                
                
                    
                    
                        <div class="add-journal-to-cart">
                            
                                <header>
                                    <a data-bind="addItem" data-key="BOOK-10153-HARDCOVER-HARDCOVER-10153-20230503-1_USD-PRINT-USD-10.1142/10153-683587" data-entity="BOOK-10153-HARDCOVER-HARDCOVER-10153-20230503-1_USD-PRINT-USD-10.1142/10153-683587" class="add-article-to-cart" href="/action/addToCart?id=BOOK-10153-HARDCOVER-HARDCOVER-10153-20230503-1_USD-PRINT-USD-10.1142/10153-683587">
                                    <span class="add-article-to-cart__title title">
                                
                                    
                                    
                                    
                                        ISBN: 978-981-3144-54-5 (hardcover)
                                    
                                
                            </span>
                                        <span class="add-article-to-cart__price price">USD 315.00</span>
                                        <span class="add-to-cart-msg">
                                        <span class="icon-Icon_Cart"></span>
                                        Add to cart
                                    </span>
                                    </a>
                                    <div class="purchaseMessage hidden info" data-item="BOOK-10153-HARDCOVER-HARDCOVER-10153-20230503-1_USD-PRINT-USD-10.1142/10153-683587">
                                        <p></p>
                                    </div>
                                </header>
                            
                            <div class="addedMessage hidden" data-item="BOOK-10153-HARDCOVER-HARDCOVER-10153-20230503-1_USD-PRINT-USD-10.1142/10153-683587">
                                <span class="article-title">
                                    <span class="article-title-content">
                                        <span class="icon-check"></span>
                                        <span class="text">
                                            
                                                
                                                
                                                
                                                    ISBN: 978-981-3144-54-5 (hardcover)
                                                
                                            
                                        </span>
                                    </span>
                                    <a href="/action/showCart?FlowID=2" class="show-cart-link">
                                            <span class="text">
                                                Checkout
                                            </span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    
                
            
                
                
                    
                    
                        <div class="add-journal-to-cart">
                            
                                <header>
                                    <a data-bind="addItem" data-key="BOOK-10153-EBOOK-ELECTRONIC-USD-10.1142/10153-489065" data-entity="BOOK-10153-EBOOK-ELECTRONIC-USD-10.1142/10153-489065" class="add-article-to-cart" href="/action/addToCart?id=BOOK-10153-EBOOK-ELECTRONIC-USD-10.1142/10153-489065">
                                    <span class="add-article-to-cart__title title">
                                
                                    
                                    
                                    
                                        ISBN: 978-981-3144-56-9 (ebook)
                                    
                                
                            </span>
                                        <span class="add-article-to-cart__price price">USD 158.00</span>
                                        <span class="add-to-cart-msg">
                                        <span class="icon-Icon_Cart"></span>
                                        Add to cart
                                    </span>
                                    </a>
                                    <div class="purchaseMessage hidden info" data-item="BOOK-10153-EBOOK-ELECTRONIC-USD-10.1142/10153-489065">
                                        <p></p>
                                    </div>
                                </header>
                            
                            <div class="addedMessage hidden" data-item="BOOK-10153-EBOOK-ELECTRONIC-USD-10.1142/10153-489065">
                                <span class="article-title">
                                    <span class="article-title-content">
                                        <span class="icon-check"></span>
                                        <span class="text">
                                            
                                                
                                                
                                                
                                                    ISBN: 978-981-3144-56-9 (ebook)
                                                
                                            
                                        </span>
                                    </span>
                                    <a href="/action/showCart?FlowID=2" class="show-cart-link">
                                            <span class="text">
                                                Checkout
                                            </span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    
                
            
        
        
    

    
</div>
        </div>
    </div>




        </div>
    











    
    
        <div data-widget-def="literatumAd" data-widget-id="2289ab35-2197-4f53-a407-db960994bd80" class="article-adv">
        



        
        



    

    

    
        
    



        </div>
    





        
        <script src="/pb-assets/wspc-site/textbookmsg/textbookmsg-1685412124033.js"></script>
<div id="textbookdisplay"><div id="textbookdisplay" style="font-family:sans-serif;background-color:#EDF4FA;border: 1px solid #000000;text-align:center;">Also available at <b><a href="http://www.amazon.com/s/ref=nb_sb_noss?url=search-alias%3Daps&amp;field-keywords=9789813144569" target="_blank">Amazon</a></b> and <b><a href="https://www.kobo.com/ebook/pattern-recognition-and-big-data" target="_blank">Kobo</a></b></div><div style="padding:0 0 10px 0;"></div></div>
<script>
var urlraw = window.location.toString().split("?");
var urlfirst = urlraw[0].split("#");
var url = urlfirst[0].split("/");
var ids="";
if(url[4] == "10.1142"){ids = url[5];}else{ids = url[6];}
var finalid = ids;
if(!textbook[finalid]){document.getElementById("textbookdisplay").innerHTML = "";}
else if(textbook[finalid] != ""){document.getElementById("textbookdisplay").innerHTML = textbook[finalid];}
</script>










    
    
        <div data-widget-def="literatumAd" data-widget-id="610fe97b-9acf-412a-9f4e-6ca05bfa2999" class="article-adv">
        



        
        



    

    

    
        
    



        </div>
    











    
    
        <div data-widget-def="literatumAd" data-widget-id="04357973-9d38-40ea-80d2-adf2a31bfbad" class="article-adv">
        



        
        



    

    

    
        
    



        </div>
    











    
    
        <div data-widget-def="literatumAd" data-widget-id="402fd859-c247-4561-a56b-395c95d8a15c" class="article-adv">
        



        
        



    
        <div class="pb-ad">
            <script>
var allurl = window.location.toString().split('?');
var rawdata = allurl[0].split('#');
var allparams = rawdata[0].split('/');
var input='';
if(allparams[5] == '10.1142'){var meters = allparams[6].split('_');input = meters[0];}
else{input = allparams[5];}
</script>
<div id="div391"><div style="padding: 0 0 10px 0;"><center><div id="eisbndisplay" style="padding: 0 5px;background-color:#EDF4FA;border: 1px solid #000000;">For institutional ebook prices, contact <a href="mailto:sales@wspc.com">sales@wspc.com</a><br>ISBN: 978-981-3144-55-2</div></center></div></div>
<script type="text/javascript">
var eisbnresult = "";
var relatedresult = "";
var subjectcrumb="";
$(document).ready(function (){
$.ajax({
   type: 'GET',
    url: 'https://misc-worldscientific-com.ezproxy.lib.hkmu.edu.hk/atypon/eisbndisplaynew.php?bookcode='+input.toLowerCase(),
    async: false,
    jsonpCallback: 'jsonCallback',
    contentType: "application/json",
    dataType: 'jsonp',
    success: function(data) {
	   $.each(data, function(index, d){
	     //alert(index);
	     if(index == "eisbndisplay")
	     {
	       eisbnresult = d;
	       //alert(eisbnresult);
	       $("#div391").html('<div style="padding: 0 0 10px 0;">'+eisbnresult+'</div>');
	     }
	     else if(index == "relateddisplay")
	     {
	       //relatedresult = d;
	       //alert(relatedresult);
	     }
	     else if(index == "subjectdisplay")
	     {
	       //subjectcrumb = d+"<br><br>";
	       //alert(subjectcrumb);
	     }
	   });
	   //$("#div391").html(eisbnresult+"<p>&nbsp;</p>");
	   //$("#relatedbooksnew").html(relatedresult);
           //$("#subjectbreadcrumb").html(subjectcrumb);
    },
    error: function(e) {
       console.log(e.message);
    }
});
});
</script>
            
        </div>
    

    

    



        </div>
    











    
    
        <div data-widget-def="literatumAd" data-widget-id="ee6f1ae6-0d99-41cb-aee8-d3df78f4a155" class="article-adv">
        



        
        



    

    

    
        
    



        </div>
    











    
    
        <div data-widget-def="literatumAd" data-widget-id="a81452ec-74be-4d80-8852-ac9ba469bb9c" class="article-adv">
        



        
        



    

    

    
        
    



        </div>
    











    
    
        <div data-widget-def="literatumAd" data-widget-id="529e1d57-57fc-415c-b35a-fe25d1115e3a" class="article-adv">
        



        
        



    

    

    
        
    



        </div>
    



</div></div></div>




        
        <div class="container"><div class="row"><div class=" col-sm-9">









    
    
        <div data-widget-def="literatumAd" data-widget-id="7ab0589a-e7d9-4c37-9fb7-d7b7919fc9cf" class="article-adv">
        



        
        



    

    

    
        
    



        </div>
    











    
    
        <div data-widget-def="UX3RelatedDigitalObject" data-widget-id="839379ef-46cd-470a-a1f7-577a516611a4" class="static-page">
        



        
        <div id="book-tabs" class="book-tabs"><div data-ctrl-res="screen-xs" class="tab  tabs--xs  clean "><ul data-mobile-toggle="dropdown" role="tablist" class="tab__nav rlist"><li role="presentation" class="tab__nav__item"><a href="#aboutBook" aria-controls="aboutBook" role="tab" data-toggle="tab" id="aboutBookcon" aria-selected="false" class="tab__nav__item__link" tabindex="-1"><span>Description</span></a></li><li role="presentation" class="tab__nav__item active"><a href="#toc" aria-controls="toc" role="tab" data-toggle="tab" id="toccon" aria-selected="true" class="tab__nav__item__link" tabindex="0"><span>Chapters</span></a></li><li role="presentation" class="tab__nav__item"><a href="#authors" aria-controls="authors" role="tab" data-toggle="tab" id="authorscon" aria-selected="false" class="tab__nav__item__link" tabindex="-1"><span>Authors</span></a></li><li role="presentation" class="tab__nav__item"><a href="#suppl" aria-controls="suppl" role="tab" data-toggle="tab" id="supplcon" aria-selected="false" class="tab__nav__item__link" tabindex="-1"><span>Supplementary</span></a></li></ul><div class="tab__content"><div id="aboutBook" aria-labelledby="aboutBookcon" role="tabpanel" class="tab__pane" aria-hidden="true"><span class="access-content">You have access to this<a href="#t=toc" class="access-for-ebook">ebook</a></span>


<!-- <description> -->
	<p>Containing twenty six contributions by experts from all over the world, this book presents both research and review material describing the evolution and recent developments of various pattern recognition methodologies, ranging from statistical, linguistic, fuzzy-set-theoretic, neural, evolutionary computing and rough-set-theoretic to hybrid soft computing, with significant real-life applications.</p>

	<p><b>Pattern Recognition and Big Data</b> provides state-of-the-art classical and modern approaches to pattern recognition and mining, with extensive real life applications. The book describes efficient soft and robust machine learning algorithms and granular computing techniques for data mining and knowledge discovery; and the issues associated with handling Big Data. Application domains considered include bioinformatics, cognitive machines (or machine mind developments), biometrics, computer vision, the e-nose, remote sensing and social network analysis.</p>
<!-- </description> -->

<!-- remove -->
<p><b>Sample Chapter(s)</b><br>
<a href="/doi/suppl/10.1142/10153/suppl_file/10153_chap01.pdf">Chapter 1: Pattern Recognition: Evolution, Mining and Big Data (411 KB)</a><br>
</p>
<!-- /remove -->
	
<!-- <contents> -->
<b>Contents:</b> 
<ul>
	<li>Pattern Recognition: Evolution, Mining and Big Data <i>(A Pal and S K Pal)</i></li>
	<li>Pattern Classification with Gaussian Processes <i>(V Stathopoulos and M Girolami)</i></li>
	<li>Active Multitask Learning using Supervised and Shared Latent Topics <i>(A Acharya, R J Mooney and J Ghosh)</i></li>
	<li>Sparse and Low-Rank Models for Visual Domain Adaptation <i>(R Chellappa and V M Patel)</i></li>
	<li>Pattern Classification using the Principle of Parsimony: Two Examples <i>(J Basak)</i></li>
	<li>Robust Learning of Classifiers in the Presence of Label Noise <i>(P S Sastry and N Manwani)</i></li>
	<li>Sparse Representation for Time-Series Classification <i>(S Bahrampour, N M Nasrabadi and A Ray)</i></li>
	<li>Fuzzy Sets as a Logic Canvas for Pattern Recognition <i>(W Pedrycz and N J Pizzi)</i></li>
	<li>Optimizing Neural Network Structures to Match Pattern Recognition Task Complexity <i>(B G Gherman, K Sirlantzis and F Deravi)</i></li>
	<li>Multi-Criterion Optimization and Decision Making Using Evolutionary Computing <i>(K Deb)</i></li>
	<li>Rough Sets in Pattern Recognition <i>(A Skowron, H S Nguyen and A Jankowski)</i></li>
	<li>The Twin SVM Minimizes the Total Risk <i>(Jayadeva, S Soman and S Chandra)</i></li>
	<li>Dynamic Kernels based Approaches to Analysis of Varying Length Patterns in Speech and Image Processing Tasks <i>(Veena T, Dileep A D and C Chandra Sekhar)</i></li>
	<li>Fuzzy Rough Granular Neural Networks for Pattern Analysis <i>(A Ganivada, S S Ray and S K Pal)</i></li>
	<li>Fundamentals of Rough-Fuzzy Clustering and Its Application in Bioinformatics <i>(P Maji and S Paul)</i></li>
	<li>Keygraphs: Structured Features for Object Detection and Applications <i>(M Hashimoto, H Morimitsu, R Hirata-Jr and R M Cesar-Jr)</i></li>
	<li>Mining Multimodal Data <i>(S Chaudhury, L Dey, I Verma and E Hassan)</i></li>
	<li>Solving Classification Problems on Human Epithelial Type 2 Cells for Anti-Nuclear Antibodies Test: Traditional versus Contemporary Approaches <i>(A Wiliem and B C Lovell)</i></li>
	<li>Representation Learning for Spoken Term Detection <i>(P R Reddy, K S R Murty and B  Yegnanarayana)</i></li>
	<li>Tongue Pattern Recognition to Detect Diabetes Mellitus and Non-Proliferative Diabetic Retinopathy <i>(B Zhang)</i></li>
	<li>Moving Object Detection using Multi-layer Markov Random Field Model <i>(B N Subudhi, S Ghosh and A Ghosh)</i></li>
	<li>Recent Advances in Remote Sensing Time Series Image Classification <i>(L Bruzzone, B Demir and F Bovolo)</i></li>
	<li>Sensor Selection for E-Nose <i>(Sunil T T, S Chaudhuri and M U Sharma)</i></li>
	<li>Understanding the Usage of Idioms in Twitter Social Network <i>(K Rudra, A Chakraborty, N Ganguly and S Ghosh)</i></li>
	<li>Sampling Theorems for Twitter: Ideas from Large Deviation Theory <i>(D Palguna, V Joshi, V Chakravarthy, R Kothari and L V Subramaniam)</i></li>
	<li>A Machine-mind Architecture and Z*-numbers for Real-world Comprehension <i>(R Banerjee and S K Pal)</i></li>
</ul>
<!-- </contents> -->

<!-- <readership> -->
<b>Readership:</b> Graduate students, researchers, academics and industry practitioners in pattern recognition.
<!-- </readership> -->










        
        <div id="trendmd-suggestions"></div>

<script defer="" src="//js.trendmd.com/trendmd.min.js" data-trendmdconfig="{&quot;element&quot;:&quot;#trendmd-suggestions&quot;}"></script>

<script async="" src="//static.zotabox.com/d/d/dd13e181780e401e8a2258e54c92eb84/widgets.js"></script> 
</div><div id="toc" aria-labelledby="toccon" role="tabpanel" class="tab__pane active" aria-hidden="false"><span class="access-content">You have access to this<a href="#t=toc" class="access-for-ebook">ebook</a></span>



        
        




        
        <!--totalCount28--><!--modified:1685468093536--><div class="table-of-content" data-enable-mathjax="true"><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i class="icon-lock_open free-access"></i><span class="badge-type badge-fa">Free Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_fmatter" title="FRONT MATTER" id="10.1142/9789813144552_fmatter">FRONT MATTER</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Pal%2C+Amita" title="Amita Pal"><span>Amita Pal</span></a>&nbsp;and&nbsp;</li><li><a href="/author/Pal%2C+Sankar+K" title="Sankar K Pal"><span>Sankar K Pal</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>i–xviii</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_fmatter">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_fmatter</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_fmatter"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_fmatter"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>The following sections are included: </p><ul class="abstractSections"><li class="section">Dedication</li><li class="section">Preface</li><li class="section">Contents</li></ul><p></p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0001" title="Chapter 1: Pattern Recognition: Evolution, Mining and Big Data" id="10.1142/9789813144552_0001">Chapter 1: Pattern Recognition: Evolution, Mining and Big Data</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Pal%2C+Amita" title="Amita Pal"><span>Amita Pal</span></a>&nbsp;and&nbsp;</li><li><a href="/author/Pal%2C+Sankar+K" title="Sankar K. Pal"><span>Sankar K. Pal</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>1–36</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0001">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0001</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0001"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0001"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>This chapter traces the evolution of pattern recognition (PR) over the years, from its humble beginnings as an extension of statistical discriminant analysis, to the multidisciplinary approach that it has become now, on account of the continuous import of ideas from various scientific disciplines. It begins with an introduction to the discipline of PR, explaining the basic underlying concepts, different tasks involved, some conventional classification techniques and the subsequent development of various modern methodologies. The evolution has been nurtured and aided by the likes of statistical decision theory, the theory of formal languages (which led to the syntactic or structural approach), followed by the theories of fuzzy sets, artificial neural networks, genetic algorithms, rough sets, granular computing and support vector machines individually (leading to different modern approaches), and finally, their integration into the theory of soft computing. While tracing the journey of pattern recognition along this complex route, significant aspects are highlighted. The chapter also discusses the significance of data mining, which has drawn the attention of many PR researchers world-wide for the past couple of decades. Finally, the challenging issues of Big Data analysis are addressed along with the relevance of PR and machine learning.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0002" title="Chapter 2: Pattern Classification with Gaussian Processes" id="10.1142/9789813144552_0002">Chapter 2: Pattern Classification with Gaussian Processes</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Stathopoulos%2C+Vassilios" title="Vassilios Stathopoulos"><span>Vassilios Stathopoulos</span></a>&nbsp;and&nbsp;</li><li><a href="/author/Girolami%2C+Mark" title="Mark Girolami"><span>Mark Girolami</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>37–73</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0002">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0002</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0002"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0002"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Recent advances in approximate inference for Gaussian processes (GP) have made possible the efficient implementation of GP models for large classification problems involving large number of classes and large number of observations. In many studies the classification performance of GP classifiers has been shown to be superior compared to other algorithms. Also with GP classifiers it is easy to handle different representations of the data which not need to be in a vectorial form and also combine information from different sources. Nevertheless, GP classifiers are not widely applied in the pattern recognition community…</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0003" title="Chapter 3: Active Multitask Learning using Supervised and Shared Latent Topics" id="10.1142/9789813144552_0003">Chapter 3: Active Multitask Learning using Supervised and Shared Latent Topics</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Acharya%2C+Ayan" title="Ayan Acharya"><span>Ayan Acharya</span></a><span>, </span></li><li><a href="/author/Mooney%2C+Raymond+J" title="Raymond J. Mooney"><span>Raymond J. Mooney</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Ghosh%2C+Joydeep" title="Joydeep Ghosh"><span>Joydeep Ghosh</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>75–112</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0003">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0003</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0003"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0003"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Multitask learning (MTL) is a machine learning technique where a problem is learnt together with other related problems at the same time, using a shared representation, so that information can be exchanged across related problems. MTL has been adopted quite frequently to alleviate problems with sparsity of labeled data across different learning tasks. Active learning, on the other hand, reduces the cost of labeling examples by making informative queries over an unlabeled pool of data. Therefore, a unification of both of these approaches can potentially be useful in settings where labeled information is expensive to obtain but the learning tasks or domains have some common characteristics. This chapter introduces frameworks that integrate MTL and active learning which make use of both latent and supervised shared topics to accomplish MTL. Experimental results on both document and image classification show that integrating MTL and active learning along with shared latent and supervised topics is superior to other methods that do not employ all of these components.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0004" title="Chapter 4: Sparse and Low-Rank Models for Visual Domain Adaptation" id="10.1142/9789813144552_0004">Chapter 4: Sparse and Low-Rank Models for Visual Domain Adaptation</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Chellappa%2C+Rama" title="Rama Chellappa"><span>Rama Chellappa</span></a>&nbsp;and&nbsp;</li><li><a href="/author/Patel%2C+Vishal+M" title="Vishal M. Patel"><span>Vishal M. Patel</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>113–133</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0004">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0004</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0004"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0004"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>In pattern recognition and computer vision, one is often faced with scenarios where the training data used to learn a model has different distribution from the data on which the model is applied. Regardless of the cause, any distributional change that occurs after learning a classifier can degrade its performance at test time. Domain adaptation tries to mitigate this degradation. This chapter presents an overview of recent domain adaptation methods based on sparse and low-rank representations.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0005" title="Chapter 5: Pattern Classification using the Principle of Parsimony: Two Examples" id="10.1142/9789813144552_0005">Chapter 5: Pattern Classification using the Principle of Parsimony: Two Examples</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Basak%2C+Jayanta" title="Jayanta Basak"><span>Jayanta Basak</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>135–166</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0005">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0005</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0005"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0005"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>The Principle of Parsimony or the Occam’s Razor is a key principle for improving the generalization performance in pattern classification. The principle is essentially equivalent to reducing the variance of a classifier at the cost of increased boundary bias. In this paper, we provide a quantitative way to express this principle in terms of the outcome of a classifier instead of explicitly regularizing the model complexity in terms of model parameters. We then use this principle to design a new kernel machine and a modified k-nearest neighbor algorithm. Experimentally we validate the performance of these two classifiers over real-life datasets. We also discuss the relationship of the proposed kernel machine with several other existing kernel machines.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0006" title="Chapter 6: Robust Learning of Classifiers in the Presence of Label Noise" id="10.1142/9789813144552_0006">Chapter 6: Robust Learning of Classifiers in the Presence of Label Noise</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Sastry%2C+P+S" title="P. S. Sastry"><span>P. S. Sastry</span></a>&nbsp;and&nbsp;</li><li><a href="/author/Manwani%2C+Naresh" title="Naresh Manwani"><span>Naresh Manwani</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>167–197</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0006">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0006</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0006"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0006"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Algorithms for learning pattern classifiesrs should, in general, be able to handle noisy training data. An important case is when the class labels in the training data are noise-corrupted. In many applications today, training data is to be obtained through crowd sourcing which naturally introduces such label noise. There are other reasons also for training data being corrupted by label noise. Many of the standard classifier learning strategies are seen to be sensitive to noisy labels in training data. Hence one needs special techniques to handle label noise. In this chapter we present an overview of some of the methods that are proposed for dealing with label noise. We elaborate more on some of the recent methods for robust learning of classifiers.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0007" title="Chapter 7: Sparse Representation for Time-Series Classification" id="10.1142/9789813144552_0007">Chapter 7: Sparse Representation for Time-Series Classification</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Bahrampour%2C+Soheil" title="Soheil Bahrampour"><span>Soheil Bahrampour</span></a><span>, </span></li><li><a href="/author/Nasrabad%2C+Nasser+M" title="Nasser M. Nasrabad"><span>Nasser M. Nasrabad</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Ray%2C+Asok" title="Asok Ray"><span>Asok Ray</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>199–215</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0007">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0007</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0007"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0007"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>This chapter studies the problem of time-series classification and presents an overview of recent developments in the area of feature extraction and information fusion. In particular, a recently proposed feature extraction algorithm, namely symbolic dynamic filtering (SDF), is reviewed. The SDF algorithm generates low-dimensional feature vectors using probabilistic finite state automata that are well-suited for discriminative tasks. The chapter also presents the recent developments in the area of sparse-representation-based algorithms for multimodal classification. This includes the joint sparse representation that enforces collaboration across all the modalities as well as the tree-structured sparsity that provides a exible framework for fusion of modalities at multiple granularities. Furthermore, unsupervised and supervised dictionary learning algorithms are reviewed. The performance of the algorithms are evaluated on a set of field data that consist of passive infrared and seismic sensors.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0008" title="Chapter 8: Fuzzy Sets as a Logic Canvas for Pattern Recognition" id="10.1142/9789813144552_0008">Chapter 8: Fuzzy Sets as a Logic Canvas for Pattern Recognition</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Pedrycz%2C+Witold" title="Witold Pedrycz"><span>Witold Pedrycz</span></a>&nbsp;and&nbsp;</li><li><a href="/author/Pizzi%2C+Nick+J" title="Nick J. Pizzi"><span>Nick J. Pizzi</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>217–253</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0008">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0008</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0008"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0008"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Imprecision and uncertainty are hallmarks of many pattern recognition problems. Although often impervious to crisp reasoning methods, these problems may be open to approximate ones. For this reason, the field has become a fertile and active domain with which to exercise fuzzy set-based modes of reasoning. For example, fuzzy sets support and enhance the design of logic-driven learning methods by: (i) formalizing prior domain knowledge; (ii) promoting hierarchical and modular architectures that exploit the most appropriate level of information granulation; (iii) providing an intuitive mapping between information couched in imprecise linguistic terminology and a well-defined contextual space. In this chapter, the authors begin with a top-down approach. They elaborate on the fundamentals of pattern recognition and fuzzy sets by focusing on the methodological issues. Subsequently, they refer to some concepts pertaining to Granular Computing and information granules. This constitutes a broader context as fuzzy sets themselves can be viewed as one of the possible realizations of information granules. Finally, they discuss some representative architectures highlighting the role of fuzzy sets.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0009" title="Chapter 9: Optimizing Neural Network Structures to Match Pattern Recognition Task Complexity" id="10.1142/9789813144552_0009">Chapter 9: Optimizing Neural Network Structures to Match Pattern Recognition Task Complexity</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Gherman%2C+B+G" title="B. G. Gherman"><span>B. G. Gherman</span></a><span>, </span></li><li><a href="/author/Sirlantzis%2C+K" title="K. Sirlantzis"><span>K. Sirlantzis</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Deravi%2C+F" title="F. Deravi"><span>F. Deravi</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>255–292</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0009">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0009</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0009"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0009"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Feed-forward neural networks are used to learn patterns in their training data. However, the problem of estimating the required size and structure of the network is still not solved. If we choose a network that is too small for a particular task, the network is unable to “comprehend” the intricacies of the data. On the other hand if we choose a network that is too big for the complexity of our problem, there is a danger of over-training. Therefore, we investigate possible ways to find the appropriate size for a modular feed-forward neural network for a given training set. Furthermore, we adopt a paradigm used by the Roman Empire and employed on a wide scale in computer programming, which is the “Divide-et-Impera” approach, to divide a given dataset into multiple sub-datasets, solve the problem for each of the subsets and fuse the results to form a solution for the initial complex problem as a whole. Our results show that, using this approach, for certain classes of pattern matching problems, it is possible to identify suitable structures that match the task complexity and thus optimize resource usage while maintaining performance levels.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0010" title="Chapter 10: Multi-Criterion Optimization and Decision Making Using Evolutionary Computing" id="10.1142/9789813144552_0010">Chapter 10: Multi-Criterion Optimization and Decision Making Using Evolutionary Computing</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Deb%2C+Kalyanmoy" title="Kalyanmoy Deb"><span>Kalyanmoy Deb</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>293–321</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0010">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0010</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0010"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0010"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Most problem solving tasks including pattern recognition activities involve more than one conicting objectives, such as accuracy, execution time, and generalization ability of a pattern matching algorithm. In such problems, there exist not one, but a number of optimal trade-off solutions. In this chapter, we discuss a number of classical and evolutionary multi-criterion optimization methods. Although no results on any pattern recognition problem has been presented, the methodologies and their scope in other problem solving tasks do not leave with much doubt about their use in different practical problem solving tasks.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0011" title="Chapter 11: Rough Sets in Pattern Recognition" id="10.1142/9789813144552_0011">Chapter 11: Rough Sets in Pattern Recognition</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Skowron%2C+Andrzej" title="Andrzej Skowron"><span>Andrzej Skowron</span></a><span>, </span></li><li><a href="/author/Son+Nguyen%2C+Hung" title="Hung Son Nguyen"><span>Hung Son Nguyen</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Jankowski%2C+Andrzej" title="Andrzej Jankowski"><span>Andrzej Jankowski</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>323–393</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0011">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0011</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0011"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0011"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>In this chapter we begin from rough set rudiments. Next we outline applications of rough sets in pattern recognition. This chapter covers partially the material presented in the chapter [272] published in 2001 in the book [184] and also includes information on development of the rough set based methods in pattern recognition published after 2001.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0012" title="Chapter 12: The Twin SVM Minimizes the Total Risk" id="10.1142/9789813144552_0012">Chapter 12: The Twin SVM Minimizes the Total Risk</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Jayadeva" title="Jayadeva"><span> Jayadeva</span></a><span>, </span></li><li><a href="/author/Soman%2C+Sumit" title="Sumit Soman"><span>Sumit Soman</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Chandra%2C+Suresh" title="Suresh Chandra"><span>Suresh Chandra</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>395–405</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0012">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0012</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0012"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0012"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>The Twin SVM (TWSVM) finds two non-parallel hyperplanes that pass through samples of the two respective classes of a binary classification problem, while lying at a distance of at least 1 from the other class. This involves solving two smaller sized Quadratic Programming Problems (QPPs) in comparison to the original SVM, and offers the advantage of insensitivity to imbalance in class sizes. This chapter points out another advantage of the TWSVM. We show that the TWSVM finds hyperplanes with a small VC dimension; in effect, the objective function of the TWSVM minimizes a linear combination of the structural and empirical risk, i.e., the TWSVM minimizes the total risk.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0013" title="Chapter 13: Dynamic Kernels based Approaches to Analysis of Varying Length Patterns in Speech and Image Processing Tasks" id="10.1142/9789813144552_0013">Chapter 13: Dynamic Kernels based Approaches to Analysis of Varying Length Patterns in Speech and Image Processing Tasks</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Thenkanidiyoor%2C+Veena" title="Veena Thenkanidiyoor"><span>Veena Thenkanidiyoor</span></a><span>, </span></li><li><a href="/author/A.+D.%2C+Dileep" title="Dileep A. D."><span>Dileep A. D.</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Chandra+Sekhar%2C+C" title="C. Chandra Sekhar"><span>C. Chandra Sekhar</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>407–485</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0013">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0013</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0013"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0013"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Varying length patterns extracted from speech and image data correspond to sets or sequences of local feature vectors. Kernels designed for varying length patterns are called as dynamic kernels. This Chapter presents the issues in designing the dynamic kernels, different methods for designing the dynamic kernels, and the suitability of dynamic kernels based approaches to speech and image processing tasks. We explore the matching based approaches to designing dynamic kernels for speech and image processing tasks. An intermediate matching kernel (IMK) for a pair of varying length patterns is constructed by matching the pairs of local feature vectors selected using a set of virtual feature vectors. For varying length patterns corresponding to sets of local feature vectors, a Gaussian mixture model (GMM) is used as the set of virtual feature vectors. The GMM-based IMK is considered for speech processing tasks such as speech emotion recognition and speaker identification, and for image processing tasks such as image classification, image matching and image annotation in content-based image retrieval. For varying length patterns corresponding to sequences of local feature vectors, a hidden Markov model (HMM) is used for selection of local feature vectors in constructing the IMK. The HMM-based IMK is considered for speech recognition tasks such as E-set recognition and Consonant-Vowel (CV) unit recognition. We present the studies comparing the IMK based approaches and the other dynamic kernels based approaches.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0014" title="Chapter 14: Fuzzy Rough Granular Neural Networks for Pattern Analysis" id="10.1142/9789813144552_0014">Chapter 14: Fuzzy Rough Granular Neural Networks for Pattern Analysis</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Ganivada%2C+Avatharam" title="Avatharam Ganivada"><span>Avatharam Ganivada</span></a><span>, </span></li><li><a href="/author/Sankar+Ray%2C+Shubhra" title="Shubhra Sankar Ray"><span>Shubhra Sankar Ray</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Pal%2C+Sankar+K" title="Sankar K. Pal"><span>Sankar K. Pal</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>487–511</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0014">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0014</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0014"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0014"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Granular computing is a computational paradigm in which a granule represents a structure of patterns evolved by performing operations on the individual patterns. Two granular neural networks are described for performing the pattern analysis tasks like classification and clustering. The granular neural networks are designed by integrating fuzzy sets and fuzzy rough sets with artificial neural networks in a soft computing paradigm. The fuzzy rough granular neural network (FRGNN) for classification is based on multi-layer neural networks. On the other hand, the fuzzy rough granular self-organizing map (FRGSOM) for clustering is based on self-organizing map. While the FRGNN uses the concepts of fuzzy rough set for defining its initial connection weights in supervised mode, the FRGSOM, as its same implies, exploits the same in unsupervised manner. Further, the input vector of FRGNN &amp; FRGSOM and the target vector of FRGNN are determined using the concepts of fuzzy sets. The performance of FRGNN and FRGSOM is compared with some of the related methods using several life data sets.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0015" title="Chapter 15: Fundamentals of Rough-Fuzzy Clustering and Its Application in Bioinformatics" id="10.1142/9789813144552_0015">Chapter 15: Fundamentals of Rough-Fuzzy Clustering and Its Application in Bioinformatics</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Maji%2C+Pradipta" title="Pradipta Maji"><span>Pradipta Maji</span></a>&nbsp;and&nbsp;</li><li><a href="/author/Paul%2C+Sushmita" title="Sushmita Paul"><span>Sushmita Paul</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>513–543</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0015">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0015</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0015"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0015"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Cluster analysis is a technique that divides a given data set into a set of clusters in such a way that two objects from the same cluster are as similar as possible and the objects from different clusters are as dissimilar as possible. In this regard, a hybrid unsupervised learning algorithm, termed as rough-fuzzy <i>c</i>-means, is presented in this chapter. It comprises a judicious integration of the principles of rough sets and fuzzy sets. While the concept of lower and upper approximations of rough sets deals with uncertainty, vagueness, and incompleteness in class definition, the membership function of fuzzy sets enables efficient handling of overlapping partitions. The concept of crisp lower approximation and fuzzy boundary of a class, introduced in rough-fuzzy <i>c</i>-means, enables efficient selection of cluster prototypes. The effectiveness of the rough-fuzzy clustering algorithm, along with a comparison with other clustering algorithms, is demonstrated on grouping functionally similar genes from microarray data, identification of co-expressed microRNAs, and segmentation of brain magnetic resonance images using standard validity indices.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0016" title="Chapter 16: Keygraphs: Structured Features for Object Detection and Applications" id="10.1142/9789813144552_0016">Chapter 16: Keygraphs: Structured Features for Object Detection and Applications</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Hashimoto%2C+M" title="M. Hashimoto"><span>M. Hashimoto</span></a><span>, </span></li><li><a href="/author/Morimitsu%2C+H" title="H. Morimitsu"><span>H. Morimitsu</span></a><span>, </span></li><li><a href="/author/Hirata%2C+R+Jr" title="R. Hirata, Jr."><span>R. Hirata, Jr.</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Cesar%2C+R+M+Jr" title="R. M. Cesar, Jr."><span>R. M. Cesar, Jr.</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>545–580</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0016">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0016</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0016"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0016"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Object detection is one of the most important problems in computer vision and it is the base for many others, such as navigation, stereo matching and augmented reality. One of the most popular and powerful choices for performing object detection is using keypoint correspondence approaches. Several keypoint detectors and descriptors have already been proposed but they often extract information from the neighborhood of each point individually, without considering the structure and relationship between them. Exploring structural pattern recognition techniques is a powerful way to fill this gap. In this chapter the concept of keygraphs is explored for extracting structural features from regular keypoints. Keygraphs provide more exibility to the description process and are more robust than traditional keypoint descriptors, such as SIFT and SURF, because they rely on structural information. The results observed in different tests show that this simplicity significantly improves the time performance, while also keeping them highly discriminative. The effectivity of keygraphs is validated by using them to detect objects in real-time applications on a mobile phone.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0017" title="Chapter 17: Mining Multimodal Data" id="10.1142/9789813144552_0017">Chapter 17: Mining Multimodal Data</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Chaudhury%2C+Santanu" title="Santanu Chaudhury"><span>Santanu Chaudhury</span></a><span>, </span></li><li><a href="/author/Dey%2C+Lipika" title="Lipika Dey"><span>Lipika Dey</span></a><span>, </span></li><li><a href="/author/Verma%2C+Ishan" title="Ishan Verma"><span>Ishan Verma</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Hassan%2C+Ehtesham" title="Ehtesham Hassan"><span>Ehtesham Hassan</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>581–604</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0017">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0017</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0017"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0017"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Multimodal data mining refers to analyzing more than one form of data for discovering hidden patterns. multimodal data analytics offer immense opportunities to integrate text, visual, audio, sensor data and structured information to derive and validate insights none of which may be possible to obtain from any single source. In this chapter, we have examined different aspects of dealing with big multimodal data. We have presented an example of cross-modal information integration between text and image. We have described an application of multi-structured data mining system for business analytics.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0018" title="Chapter 18: Solving Classification Problems on Human Epithelial Type 2 Cells for Anti-Nuclear Antibodies Test: Traditional versus Contemporary Approaches" id="10.1142/9789813144552_0018">Chapter 18: Solving Classification Problems on Human Epithelial Type 2 Cells for Anti-Nuclear Antibodies Test: Traditional versus Contemporary Approaches</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Wiliem%2C+Arnold" title="Arnold Wiliem"><span>Arnold Wiliem</span></a>&nbsp;and&nbsp;</li><li><a href="/author/Lovell%2C+Brian+C" title="Brian C. Lovell"><span>Brian C. Lovell</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>605–632</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0018">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0018</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0018"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0018"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Pathology tests play a major role in our health care system and they assist physicians to make accurate diagnoses. Recently, there has been growing interest in developing Computer-Aided Diagnostic (CAD) systems which should further improve the reliability and consistency of these tests. We discuss the Anti-Nuclear Antibodies (ANA) test via Indirect Immunouorescence protocol on Human Epithelial Type 2 (HEp-2) cells which is normally used to determine the presence of Connective Tissue Diseases such as Sjögren’s syndrome, Systemic Lupus Erythematosus and Rheumatoid Arthritis. One task in the test is to determine the pattern of positive HEp-2 cells. This chapter discusses and compares both traditional and contemporary approaches to this problem via image-based analysis. Whilst, the traditional approaches comprise several popular methods used to address generic image classification problems, the contemporary approaches apply advanced mathematical techniques to improve system accuracy. Specifically, our discussion focuses on features that reside in a non-linear statistical manifold space.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0019" title="Chapter 19: Representation Learning for Spoken Term Detection" id="10.1142/9789813144552_0019">Chapter 19: Representation Learning for Spoken Term Detection</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Raghavendra+Reddy%2C+P" title="P. Raghavendra Reddy"><span>P. Raghavendra Reddy</span></a><span>, </span></li><li><a href="/author/Sri+Rama+Murty%2C+K" title="K. Sri Rama Murty"><span>K. Sri Rama Murty</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Yegnanarayana%2C+B" title="B. Yegnanarayana"><span>B. Yegnanarayana</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>633–662</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0019">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0019</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0019"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0019"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Spoken Term Detection (STD), which refers to the task of searching for a user audio query in audio data is extremely significant for the management and monitoring of increasing volumes of audio data on the internet. It is affected by channel mismatch, speaker variability and differences in speaking mode/rate. Thus one of the main issues in STD is to devise a robust and speaker-invariant representation for the speech signal, so that the query and reference utterances can be matched in the new representation domain. In this chapter, the authors compare and contrast the supervised and unsupervised approaches to learn robust speech-specific representation for the STD task. Posterior representation of speech is used for developing the STD system with posterior features extracted in both supervised and unsupervised approaches.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0020" title="Chapter 20: Tongue Pattern Recognition to Detect Diabetes Mellitus and Non-Proliferative Diabetic Retinopathy" id="10.1142/9789813144552_0020">Chapter 20: Tongue Pattern Recognition to Detect Diabetes Mellitus and Non-Proliferative Diabetic Retinopathy</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Zhang%2C+Bob" title="Bob Zhang"><span>Bob Zhang</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>663–686</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0020">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0020</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0020"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0020"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>Diabetes Mellitus (DM) and its complications leading to Diabetic Retinopathy (DR) are soon to become one of the 21st century’s major health problems. This represents a huge financial burden to healthcare officials and governments. To combat this approaching epidemic, this chapter proposes a non-invasive method to detect DM and Nonproliferative Diabetic Retinopathy (NPDR) the initial stage of DR based on three groups of features extracted from tongue images. They include color, texture and geometry. A non-invasive capture device with image correction first captures the tongue images. A tongue color gamut is established with 12 colors representing the tongue color features. The texture values of 8 blocks strategically located on the tongue surface, with the additional mean of all 8 blocks is used to characterize the 9 tongue texture features. Lastly, 13 features extracted from tongue images based on measurements, distances, areas, and their ratios represent the geometry features. Applying a combination of the 34 features, the proposed method can separate Healthy/DM tongues as well as NPDR/DM-sans NPDR (DM samples without NPDR) tongues using features from each of the three groups with average accuracies of 80.52% and 80.33%, respectively. This is on a database consisting of 130 Healthy and 296 DM samples, where 29 of those in DM are NPDR.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0021" title="Chapter 21: Moving Object Detection using Multi-layer Markov Random Field Model" id="10.1142/9789813144552_0021">Chapter 21: Moving Object Detection using Multi-layer Markov Random Field Model</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Narayan+Subudhi%2C+Badri" title="Badri Narayan Subudhi"><span>Badri Narayan Subudhi</span></a><span>, </span></li><li><a href="/author/Ghosh%2C+Susmita" title="Susmita Ghosh"><span>Susmita Ghosh</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Ghosh%2C+Ashish" title="Ashish Ghosh"><span>Ashish Ghosh</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>687–711</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0021">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0021</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0021"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0021"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>In this work, a multi-layer Markov model based spatio-temporal segmentation scheme for moving object detection is proposed. Spatial segmentation for initial frame is obtained by multi-layer compound Markov random field (MLCMRF) followed by MAP estimation with a combination of simulated annealing (SA) and iterative conditional mode (ICM) techniques. For subsequent frames, a change information based heuristic initialization is proposed for faster convergence of the MAP estimation. For temporal segmentation, label difference based change detection technique is proposed. In one of them, we have considered label frame difference followed by Otsu’s thresholding for change detection mask (CDM) generation and in the other, we have proposed label frame difference followed by entropy associated window selection for CDM generation. This CDM is further modified with the video object planes (VOPs) from the previous frame to identify the locations of the moving objects. The results obtained by the proposed technique are compared with those of the existing state-of-the-art techniques and are found to be better.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0022" title="Chapter 22: Recent Advances in Remote Sensing Time Series Image Classification" id="10.1142/9789813144552_0022">Chapter 22: Recent Advances in Remote Sensing Time Series Image Classification</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Bruzzone%2C+Lorenzo" title="Lorenzo Bruzzone"><span>Lorenzo Bruzzone</span></a><span>, </span></li><li><a href="/author/Demir%2C+Beg%C3%BCm" title="Begüm Demir"><span>Begüm Demir</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Bovolo%2C+Francesca" title="Francesca Bovolo"><span>Francesca Bovolo</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>713–734</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0022">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0022</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0022"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0022"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>This chapter revises the recent advances in the automatic classification of remote sensing (RS) image time series (images regularly acquired by satellite-borne sensors on the same areas at different times) to update land-cover maps. The availability of up-to-date land-cover maps has significant impacts on several aspects of daily life from the economical, administrative and management point of view. Thus land-cover maps updating by classification of RS images is an hot topic. This is even more true since an increasing number of image time series are being acquired and freely available for a large number of satellite missions (<i>e.g</i>., Landsat archive, ESA Sentinel missions). Land-cover maps can be updated by direct supervised classification of each image in the time series. However, in order to properly train the classifier such an approach requires reliable ground reference data for each available temporal image. In operational scenarios, gathering a suffcient number of labeled training samples for each single image to be classified is not realistic due to the high cost and the related time consuming process of this task. To overcome these problems, domain adaptation (DA) methods have been recently intro- duced in the RS literature. Accordingly, in this chapter the most recent methodological developments related to DA are presented and discussed by focusing on semi-supervised and active learning approaches. Finally, the most promising methods to define low-cost training sets and to effectively classify RS image time series will be discussed.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0023" title="Chapter 23: Sensor Selection for E-Nose" id="10.1142/9789813144552_0023">Chapter 23: Sensor Selection for E-Nose</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Sunil%2C+T+T" title="T. T. Sunil"><span>T. T. Sunil</span></a><span>, </span></li><li><a href="/author/Chaudhuri%2C+Subhasis" title="Subhasis Chaudhuri"><span>Subhasis Chaudhuri</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Sharma%2C+M+U" title="M. U. Sharma"><span>M. U. Sharma</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>735–765</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0023">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0023</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0023"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0023"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>The following sections are included: </p><ul class="abstractSections"><li class="section">Introduction</li><li class="section">Experimental setup</li><li class="section">Gas detection</li><li class="section">Sensor selection</li><li class="section">Conclusions</li><li class="section">Acknowledgment</li><li class="section">References</li></ul><p></p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0024" title="Chapter 24: Understanding the Usage of Idioms in the Twitter Social Network" id="10.1142/9789813144552_0024">Chapter 24: Understanding the Usage of Idioms in the Twitter Social Network</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Rudra%2C+Koustav" title="Koustav Rudra"><span>Koustav Rudra</span></a><span>, </span></li><li><a href="/author/Chakraborty%2C+Abhijnan" title="Abhijnan Chakraborty"><span>Abhijnan Chakraborty</span></a><span>, </span></li><li><a href="/author/Ganguly%2C+Niloy" title="Niloy Ganguly"><span>Niloy Ganguly</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Ghosh%2C+Saptarshi" title="Saptarshi Ghosh"><span>Saptarshi Ghosh</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>767–788</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0024">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0024</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0024"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0024"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>To help users find popular topics of discussion, Twitter periodically publishes ‘trending topics’ (trends) which are the most discussed keywords (e.g., hashtags) at a certain point of time. Inspection of the trends over several months reveals that while most of the trends are related to events in the off-line world, such as popular television shows, sports events, or emerging technologies, a significant fraction are <i>not</i> related to any topic / event in the off-line world. Such trends are usually known as <i>idioms</i>, examples being #4WordsBeforeBreakup , #10thingsIHateAboutYou , etc. We perform the first systematic measurement study on Twitter idioms. We find that tweets related to a particular idiom normally do not cluster around any particular topic or event. There are a set of users in Twitter who predominantly discuss idioms – common, not-so-popular, but active users who mostly use Twitter as a conversational platform – as opposed to other users who primarily discuss topical contents. The implication of these findings is that within a single online social network, activities of users may have very different semantics; thus, tasks like community detection and recommendation may not be accomplished perfectly using a single universal algorithm. Specifically, we run two (link-based and content-based) algorithms for community detection on the Twitter social network, and show that the idiom oriented users get clustered better in one while topical users in the other.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0025" title="Chapter 25: Sampling Theorems for Twitter: Ideas from Large Deviation Theory" id="10.1142/9789813144552_0025">Chapter 25: Sampling Theorems for Twitter: Ideas from Large Deviation Theory</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Palguna%2C+Deepan" title="Deepan Palguna"><span>Deepan Palguna</span></a><span>, </span></li><li><a href="/author/Joshi%2C+Vikas" title="Vikas Joshi"><span>Vikas Joshi</span></a><span>, </span></li><li><a href="/author/Chakravarthy%2C+Venkatesan" title="Venkatesan Chakravarthy"><span>Venkatesan Chakravarthy</span></a><span>, </span></li><li><a href="/author/Kothari%2C+Ravi" title="Ravi Kothari"><span>Ravi Kothari</span></a>,&nbsp;and&nbsp;</li><li><a href="/author/Subramaniam%2C+L+V" title="L. V. Subramaniam"><span>L. V. Subramaniam</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>789–803</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0025">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0025</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0025"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0025"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>The daily volume of Tweets generated by Twitter is around 500 million, and the impact of this data on applications ranging from public safety, opinion mining, news broadcast, etc., is increasing day by day. Analyzing large volumes of Tweets for various applications would require techniques that scale well with the number of Tweets. In this chapter we discuss a theoretical formulation for sampling Twitter data. Metrics to quantify the statistical representativeness of the Tweet samples are introduced, and results on the number of samples sufficient to obtain highly representative Tweet samples are derived. These statistical metrics quantify the representativeness or goodness of the sample in terms of restoring public sentiments associated with these frequent keywords. Sampling a sufficient number of Tweets uniformly and randomly could serve as a first step before using other sophisticated summarization methods to generate summaries for human use. Experiments conducted on real Twitter data are provided as examples to show how the bounds behave in practice. Moreover, we compare different kinds of random sampling algorithms in these experiments. The bounds derived are attractive since they do not depend on the total number of Tweets in the universe. Although these ideas and techniques are specific to Twitter, they could find applications in other areas as well.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i aria-hidden="true" class="icon-lock_open full-access"></i><span class="badge-type badge-full">Full Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_0026" title="Chapter 26: A Machine-mind Architecture and Z*-numbers for Real-world Comprehension" id="10.1142/9789813144552_0026">Chapter 26: A Machine-mind Architecture and Z*-numbers for Real-world Comprehension</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Banerjee%2C+Romi" title="Romi Banerjee"><span>Romi Banerjee</span></a>&nbsp;and&nbsp;</li><li><a href="/author/Pal%2C+Sankar+K" title="Sankar K. Pal"><span>Sankar K. Pal</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>805–842</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0026">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_0026</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_0026"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_0026"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>This article documents our efforts on machine-mind design for real-world, understanding. It includes: a) enumeration of essential macro-architectural elements and working principle of our machine-mind framework, b) definition of a novel paradigm, the Z*-numbers, for encapsulation of essential objective and subjective elements of real-world information, and c) a detailed example illustrating the dynamics of the framework and the role of the Z*-numbers. Our work is based on Minsky’s theories of cognition, Zadeh’s Z-number philosophy, and human brain processes of comprehension. The ideas herein, envision man-machine symbiosis and aim to contribute to the synthesis of an empathetic artificial mind. Among others, the primary novelty in our design lies in the emphasis on representation of the machine-self and its derivates towards emulation of bespoke real-world comprehension.</p></div></div></div></div><div class="issue-item"><div class="badges"><div class="badges__access__wrapper"><i class="icon-lock_open free-access"></i><span class="badge-type badge-fa">Free Access</span></div></div><h5 class="issue-item__title"><a href="/doi/10.1142/9789813144552_bmatter" title="BACK MATTER" id="10.1142/9789813144552_bmatter">BACK MATTER</a></h5><ul class="rlist--inline loa" aria-label="author"><li><a href="/author/Pal%2C+Amita" title="Amita Pal"><span>Amita Pal</span></a>&nbsp;and&nbsp;</li><li><a href="/author/Pal%2C+Sankar+K" title="Sankar K Pal"><span>Sankar K Pal</span></a></li></ul><ul class="rlist--inline separator toc-item__detail"><li><span>Pages:</span>843–856</li></ul><p><a href="https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_bmatter">https://doi-org.ezproxy.lib.hkmu.edu.hk/10.1142/9789813144552_bmatter</a></p><div class="specialAbstract"></div><div class="toc-item__footer"><ul class="rlist--inline separator toc-item__detail"><li><a title="Abstract" href="/doi/abs/10.1142/9789813144552_bmatter"><span>Abstract</span><i class="icon icon-abstract"></i></a></li><li><a title="PDF/EPUB" href="/doi/reader/10.1142/9789813144552_bmatter"><span>PDF/EPUB</span><i class="icon icon-file-pdf"></i></a></li></ul><div class="accordion"><a href="#" title="Preview Abstract" class="accordion__control" aria-expanded="false"><i class="icon-section_arrow_d"></i>Preview Abstract</a><div class="accordion__content toc-item__abstract" style="display: none !important;"><p>The following sections are included: </p><ul class="abstractSections"><li class="section">Author Index</li><li class="section">Subject Index</li><li class="section">About the Editors</li></ul><p></p></div></div></div></div></div>
</div><div id="authors" aria-labelledby="authorscon" role="tabpanel" class="tab__pane" aria-hidden="true"><span class="access-content">You have access to this<a href="#t=toc" class="access-for-ebook">ebook</a></span>


<img src="/pb-assets/wspc-site/books/authors/amita_pal-1584414270113.jpg" width="100">
<p><b>Amita Pal</b> (nee Pathak) is currently an Associate Professor in the faculty of Indian Statistical Institute, Kolkata, India, in the Bayesian and Interdisciplinary Research Unit. She had graduated with honours in Statistics from Presidency College, Kolkata, in 1979, and subsequently obtained an MSc in Statistics from the University of Calcutta, India, in 1981, and a PhD from the Indian Statistical Institute, Kolkata, India, in 1991. She visited the Department of Mathematics of the Imperial College of Science, Technology and Medicine, London, on a six-month UNDP fellowship in 1994, and joined the faculty of Indian Statistical Institute, Kolkata, in the same year. Her research interests are mainly in the areas of pattern recognition and image processing.</p>

<br>

<img src="/pb-assets/wspc-site/books/authors/sankar_k_pal-1584414300203.jpg" width="100">
<p><b>Sankar K Pal</b> is a Distinguished Scientist and former Director of the Indian Statistical Institute Kolkata, India. He is a DAE Raja Ramanna Fellow and J C Bose Fellow of the Government of India, and former INAE Chair Professor. He founded the Machine Intelligence Unit and the Center for Soft Computing Research in the Indian Statistical Institute in Kolkata. He obtained two PhDs from Calcutta University, India, and Imperial College, London; and worked at the UC Berkeley and UMD, College Park; the NASA JSC, Houston, Texas; and US Naval Research Lab, Washington DC. He served as a Distinguished Visitor of IEEE Computer Society and held visiting positions in Italy, Poland, Hong Kong and Australian universities. Prof Pal is a Life-Fellow of IEEE and Fellow of TWAS, IAPR, IFSA and INSA. He is a co-author of nineteen books and more than four hundred research publications. He has served in the editorial board of twenty international journals, including IEEE transactions. Awards/prizes received include the S S Bhatnagar Prize (India), the Padma Shri (India), the Khwarizmi International Award (Iran) and the NASA Tech. Brief award (USA).</p>


</div><div id="suppl" aria-labelledby="supplcon" role="tabpanel" class="tab__pane" aria-hidden="true"><span class="access-content">You have access to this<a href="#t=toc" class="access-for-ebook">ebook</a></span>



        
        <!-- remove -->
<p><b>Sample Chapter(s)</b><br>
<a href="/doi/suppl/10.1142/10153/suppl_file/10153_chap01.pdf">Chapter 1: Pattern Recognition: Evolution, Mining and Big Data (411 KB)</a><br>
</p>
<!-- /remove -->
</div></div></div></div>

        </div>
    

</div><div class=" col-sm-3">



        
        



    
        <div class="pb-ad">
             <a href="/action/clickThrough?id=104631&amp;url=https%3A%2F%2Fworldscientific.com%2Fpage%2Fengineering-subscribe%3Futm_source%3Dwebsite%26utm_medium%3Dad-placeholder%26utm_campaign%3Daction-law-26092022-engineeringsubscribeform&amp;loc=%2Fworldscibooks%2F10.1142%2F10153&amp;pubId=41547515&amp;placeholderId=1069&amp;productId=103012"> <img src="/sda/1488/engineeringsubscribe.png"></a><p>
            
        </p></div>
    

    

    






        
        



    

    

    
        
    






        
        



    

    

    
        
    






        
        



    
        <div class="pb-ad">
            &nbsp;
<a href="/action/clickThrough?id=104312&amp;url=https%3A%2F%2Fwww.worldscientific.com%2Fpage%2Fannual-catalogues+&amp;loc=%2Fworldscibooks%2F10.1142%2F10153&amp;pubId=41547515&amp;placeholderId=1070&amp;productId=1413"><img src="/sda/1488/ac2021.jpg"></a><p>
            
        </p></div>
    

    

    






        
        



    
        <div class="pb-ad">
            <p> <a href="/action/clickThrough?id=104170&amp;url=%2Ftopic%2Fmktcode-ee000%3Ftarget%3DbookTitleSearch%26content%3DbookTitle%26sortBy%3DEarliest%26startPage%3D%26Ppub%3D%255B20200101%2520TO%252020221231%255D&amp;loc=%2Fworldscibooks%2F10.1142%2F10153&amp;pubId=41547515&amp;placeholderId=1087&amp;productId=1419">

 <img src="/sda/1488/NewTitlesEngineering.jpg"> </a>  
            
        </p></div>
    

    

    


</div></div></div>




        
        <div class="container"><div class="row"><div>









    
    
        <div data-widget-def="UX3RelatedDigitalObject" data-widget-id="6dfde029-eafe-4270-afe8-d668ca5aa6dd" class="grid-sm-2 home-sections bottom-margin">
        



        
        <div class="books__slider responsiveSlider5-3-2-1"><h3 class="section__header border-bottom">Related Books</h3><div class="slideShow"><div data-items="1" data-slideby="1" data-responsive="{&quot;xsMin&quot;:{&quot;items&quot;:1},&quot;smMin&quot;:{&quot;items&quot;:2},&quot;mdMin&quot;:{&quot;items&quot;:4}}" data-speed="2500" data-autoplay="false" data-animation="slide" data-indicators="false" data-arrow="true" data-controls="false" data-stagepadding="0" class="owl-carousel owl-loaded owl-drag" data-pause-slide="Pause slideshow" data-play-slide="Play slideshow" data-go-to-slide="Go to slide:" data-next-slide="Go to next slide" data-prev-slide="Go to previous slide" tabindex="0"><div class="owl-stage-outer"><div class="owl-stage" style="transform: translate3d(0px, 0px, 0px); transition: all 0s ease 0s; width: 5168px;"><div class="owl-item active first" style="width: 272px;" aria-current="true"><div class="slide-item"><a href="/worldscibooks/10.1142/9503" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/books/2016/9503/9503/20150112/9503.cover.jpg" class="cover-image"><h3>Handbook of Pattern Recognition and Computer Vision</h3></a></div></div><div class="owl-item active" style="width: 272px;" aria-current="true"><div class="slide-item"><a href="/worldscibooks/10.1142/11353" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/smpai/2020/11353/11353/20200818-01/11353.cover.jpg" class="cover-image"><h3>Handwritten Historical Document Analysis, Recognition, and Retrieval — State of the Art and Future Trends</h3></a></div></div><div class="owl-item active" style="width: 272px;" aria-current="true"><div class="slide-item"><a href="/worldscibooks/10.1142/10775" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/books/2023/10775/10775/20220217-01/10775.cover.jpg" class="cover-image"><h3>Quantum Mechanics and Bayesian Machines</h3></a></div></div><div class="owl-item active" style="width: 272px;" aria-current="true"><div class="slide-item"><a href="/worldscibooks/10.1142/10552" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/scv/2024/10552/10552/20230330-01/10552.cover.jpg" class="cover-image"><h3>Handbook of Random Forests</h3></a></div></div><div class="owl-item active" style="width: 272px;" aria-current="true"><div class="slide-item"><a href="/worldscibooks/10.1142/p724" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/csp/2011/p724/p724/production/p724.cover.jpg" class="cover-image"><h3>Audio-Visual Person Tracking</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/11325" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/smpai/2019/11325/11325/20190118-01/11325.cover.jpg" class="cover-image"><h3>Ensemble Learning</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/10689" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/smpai/2018/10689/10689/20170622/10689.cover.jpg" class="cover-image"><h3>Document Analysis and Text Recognition</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/3414" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/books/1999/3414/3414/production/3414.cover.jpg" class="cover-image"><h3>Handbook of Pattern Recognition and Computer Vision</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/9815" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/books/2015/9815/9815/20151020-01/9815.cover.jpg" class="cover-image"><h3>Sparse Coding and its Applications in Computer Vision</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/3641" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/smpai/1999/3641/3641/production/3641.cover.jpg" class="cover-image"><h3>Introduction to Pattern Recognition</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/1802" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/books/1993/1802/1802/production/1802.cover.jpg" class="cover-image"><h3>Handbook of Pattern Recognition and Computer Vision</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/9833" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/scv/2016/9833/9833/20150831/9833.cover.jpg" class="cover-image"><h3>Discrete Fractional Calculus</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/p155" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/books/2000/p155/p155/production/p155.cover.jpg" class="cover-image"><h3>Dynamic Vision</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/10835" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/books/2019/10835/10835/20190124-01/10835.cover.jpg" class="cover-image"><h3>Facial Multi-Characteristics and Applications</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/5119" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/books/2002/5119/5119/production/5119.cover.jpg" class="cover-image"><h3>Digital Video Transition Analysis and Detection</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/11216" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/scv/2019/11216/11216/20180924/11216.cover.jpg" class="cover-image"><h3>Syntactic Pattern Recognition</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/9866" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/books/2016/9866/9866/20150920/9866.cover.jpg" class="cover-image"><h3>Face Processing and Applications to Distance Learning</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/11361" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/wsescri/2019/11361/11361/20190128-01/11361.cover.jpg" class="cover-image"><h3>Robotic Intelligence</h3></a></div></div><div class="owl-item" style="width: 272px;" aria-current="false"><div class="slide-item"><a href="/worldscibooks/10.1142/9024" class="books__slider__item"><img src="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/na101/home/literatum/publisher/wspc/books/content/books/2024/9024/9024/20230222-01/9024.cover.jpg" class="cover-image"><h3>Hands-On Computer Vision</h3></a></div></div></div></div><div class="owl-nav"><button type="button" role="button" class="owl-prev disabled" title="Previous" tabindex="0"><span class="sr-only">prev</span><i class="icon-arrow_l"></i></button><button type="button" role="button" class="owl-next owl-nav-active" title="Next" tabindex="0"><span class="sr-only">next</span><i class="icon-arrow_r"></i></button></div><div class="owl-dots disabled"></div></div></div></div>

        </div>
    

</div></div></div>
<div class="w-slide"><div class="w-slide_head"><a href="#" class="w-slide__back"><i class=" icon-arrow_l" aria-hidden="true"></i>back</a><span class="w-slide__title"></span></div><div class="w-slide__content"></div></div></main>




        
        <footer>









    
    
        <div data-widget-def="ux3-layout-widget" data-widget-id="81a18a14-d709-41fd-9bb6-25a7fc1e13df" class="footer-top clearfix">
        



        
        <div class="container"><div class="row"><div class="col-sm-3">



        
        <a href="/" title="World Sientific Logo"><img id="" alt="World Sientific Logo" src="/pb-assets/releasedAssets/images/WSPClogo-white.png"></a>




        
        <center>
<p></p>
<div style="display: inline-block;">
<a href="https://www.facebook.com/worldscientific" target="blank"><img src="/pb-assets/wspc-site/icons/facebookicon-1533103772177.png"></a>
</div>
<div style="display: inline-block;">
<a href="https://twitter.com/worldscientific" target="blank"><img src="/pb-assets/wspc-site/icons/twittericon-1533103772437.png"></a>
</div>
<div style="display: inline-block;">
<a href="https://www.linkedin.com/company/world-scientific-publishing/" target="blank"><img src="/pb-assets/wspc-site/icons/linkedinicon-1533103772177.png"></a>
</div>
<div style="display: inline-block;">
<a href="https://www.youtube.com/channel/UCDw6b_X0ccpwcc78iMjsI_Q" target="blank"><img src="/pb-assets/wspc-site/icons/youtubeicon-1533103772463.png"></a>
</div>
<div style="display: inline-block;">
<a href="https://www-worldscientific-com.ezproxy.lib.hkmu.edu.hk/page/newsletter/subscribe" target="blank"><img src="/pb-assets/wspc-site/icons/emailicon-1533103772177.png"></a>
</div>
<div style="display: inline-block;">
<a href="https://china-worldscientific-com.ezproxy.lib.hkmu.edu.hk/wechat-qr-code/" target="blank"><img src="/pb-assets/wspc-site/icons/wechaticon-1533103772450.png"></a>
</div>
</center>
</div><div class="col-lg-7 col-lg-offset-2 sitemap hidden-xs hidden-sm col-sm-9">



        
        <div class=" col-sm-4">



        
        <h5 class="border-top">Resources</h5>
<ul class="rlist">
    <li class="mikefooterlist"><a href="/page/authors/index">For Authors</a></li>
    <li class="mikefooterlist"><a href="/page/booksellers">For Booksellers</a></li>
    <li class="mikefooterlist"><a href="/page/librarians">For Librarians</a></li>
    <li class="mikefooterlist"><a href="/page/permissions">Copyright &amp; Permissions</a></li>
    <li class="mikefooterlist"><a href="/page/translation-rights">Translation Rights</a></li>
    <li class="mikefooterlist"><a href="/page/help/how-to-order">How to Order</a></li>
    <li class="mikefooterlist"><a href="/page/contactus">Contact Us</a></li>
    <li class="mikefooterlist"><a href="/page/sitemap">Sitemap</a></li>
</ul>
<br>&nbsp;
</div><div class=" col-sm-4">



        
        <h5 class="border-top">About Us &amp; Help</h5>
<ul class="rlist">
    <li class="mikefooterlist">
        <a href="/page/about/corporate-profile">About Us</a>
    </li>
    <li class="mikefooterlist">
        <a href="/page/pressroom">News</a>
    </li>
    <li class="mikefooterlist">
        <a href="/page/help">Help</a>
    </li>
</ul>
</div><div class=" col-sm-4">



        
        <style>
.mikefooterlist:hover{color: #ADD8E6;}
</style>
<h5 class="border-top">Links</h5>
<ul class="rlist">
    <li class="mikefooterlist">
        <a href="https://europe-worldscientific-com.ezproxy.lib.hkmu.edu.hk/" target="blank">World Scientific Europe</a>
    </li>
    <li class="mikefooterlist">
        <a href="https://china-worldscientific-com.ezproxy.lib.hkmu.edu.hk/" target="blank">World Scientific China 世界科技</a>
    </li>
    <li class="mikefooterlist">
        <a href="https://worldscientificedu.com/" target="blank">WS Education (K-12)</a>
    </li>
    <li class="mikefooterlist">
        <a href="https://www.globalpublishing.com.sg/" target="blank">Global Publishing 八方文化</a>
    </li>
    <li class="mikefooterlist">
        <a href="https://www.asiabiotech.com/" target="blank">Asia-Pacific Biotech News</a>
    </li>
    <li class="mikefooterlist">
        <a href="https://www.worldcenturypublishing.com/" target="blank">World Century</a>
    </li>
</ul>
</div>
</div></div></div>

        </div>
    











    
    
        <div data-widget-def="ux3-layout-widget" data-widget-id="6e6da9b7-371e-4ea0-827e-8de5915b8cd5" class="footer-bottom text-onDark clearfix">
        



        
        <div class="container"><div class="row"><div class=" col-md-6">



        
        <ul class="rlist--inline separator">
    <!--<li>
        <a href="/terms">Terms and conditions</a>
    </li>-->
    <li>
        <a href="/page/help/privacy-policy">Privacy policy</a>
    </li>
</ul>
</div><div class=" col-md-6">



        
        <div class="copyright">© 2023 World Scientific Publishing Co Pte Ltd
<div>Powered by Atypon® Literatum</div>
</div>


</div></div></div>

        </div>
    

</footer>




        
        <!-- Bot analytics test -->
<script src="https://api.b2c.com/api/init-260u9k3l7hxtcferh76.js" data-cfasync="false" async=""></script>
<noscript><img src="https://api.b2c.com/api/noscript-260u9k3l7hxtcferh76.gif"></noscript>





        
        <script>
  !function(g,s,q,r,d){r=g[r]=g[r]||function(){(r.q=r.q||[]).push(
  arguments)};d=s.createElement(q);q=s.getElementsByTagName(q)[0];
  d.src='//d1l6p2sc9645hc.cloudfront.net/tracker.js';q.parentNode.
  insertBefore(d,q)}(window,document,'script','_gs');

  _gs('GSN-226025-N');
</script>




        
        <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NVG6FP"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->




        
        <link rel="stylesheet" type="text/css" href="/pb-assets/Custom-CCS/bookpage-1609294503327.css">




        
        <script type="text/javascript">
(function(e,a){
var t,r=e.getElementsByTagName("head")[0],c=e.location.protocol;
t=e.createElement("script");t.type="text/javascript";
t.charset="utf-8";t.async=!0;t.defer=!0;
t.src=c+"//front.optimonk.com/public/"+a+"/js/preload.js";r.appendChild(t);
})(document,"175445");
</script>
        </div>
    </div>

<script type="text/javascript" id="">!function(d,e,f,a,b,c){d.qp||(a=d.qp=function(){a.qp?a.qp.apply(a,arguments):a.queue.push(arguments)},a.queue=[],b=document.createElement(e),b.async=!0,b.src=f,c=document.getElementsByTagName(e)[0],c.parentNode.insertBefore(b,c))}(window,"script","https://a.quora.com/qevents.js");qp("init","544b1d21775a45b58d4e3e93112f4b02");qp("track","ViewContent");</script>
<noscript><img height="1" width="1" style="display:none" src="https://q.quora.com/_/ad/544b1d21775a45b58d4e3e93112f4b02/pixel?tag=ViewContent&amp;noscript=1"></noscript>

<script type="text/javascript" id="">qp("track","Generic");</script>
<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","162493725769742");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=162493725769742&amp;ev=PageView&amp;noscript=1"></noscript>

<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","731609284183339");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=731609284183339&amp;ev=PageView&amp;noscript=1"></noscript>

<script type="text/javascript" id="">!function(d,e,f,a,b,c){d.twq||(a=d.twq=function(){a.exe?a.exe.apply(a,arguments):a.queue.push(arguments)},a.version="1.1",a.queue=[],b=e.createElement(f),b.async=!0,b.src="//static.ads-twitter.com/uwt.js",c=e.getElementsByTagName(f)[0],c.parentNode.insertBefore(b,c))}(window,document,"script");twq("init","o87ad");twq("track","PageView");</script>

<script type="text/javascript" id="">!function(d,e,f,a,b,c){d.twq||(a=d.twq=function(){a.exe?a.exe.apply(a,arguments):a.queue.push(arguments)},a.version="1.1",a.queue=[],b=e.createElement(f),b.async=!0,b.src="//static.ads-twitter.com/uwt.js",c=e.getElementsByTagName(f)[0],c.parentNode.insertBefore(b,c))}(window,document,"script");twq("init","o89at");twq("track","PageView");</script>

<script type="text/javascript" id="">!function(d,e,f,a,b,c){d.twq||(a=d.twq=function(){a.exe?a.exe.apply(a,arguments):a.queue.push(arguments)},a.version="1.1",a.queue=[],b=e.createElement(f),b.async=!0,b.src="//static.ads-twitter.com/uwt.js",c=e.getElementsByTagName(f)[0],c.parentNode.insertBefore(b,c))}(window,document,"script");twq("init","o8xe5");twq("track","PageView");</script>

<script type="text/javascript" id="">!function(d,e,f,a,b,c){d.twq||(a=d.twq=function(){a.exe?a.exe.apply(a,arguments):a.queue.push(arguments)},a.version="1.1",a.queue=[],b=e.createElement(f),b.async=!0,b.src="//static.ads-twitter.com/uwt.js",c=e.getElementsByTagName(f)[0],c.parentNode.insertBefore(b,c))}(window,document,"script");twq("init","o93q7");twq("track","PageView");</script>

<script type="text/javascript" id="">!function(d,e,f,a,b,c){d.twq||(a=d.twq=function(){a.exe?a.exe.apply(a,arguments):a.queue.push(arguments)},a.version="1.1",a.queue=[],b=e.createElement(f),b.async=!0,b.src="//static.ads-twitter.com/uwt.js",c=e.getElementsByTagName(f)[0],c.parentNode.insertBefore(b,c))}(window,document,"script");twq("init","o9kyw");twq("track","PageView");</script>

<script type="text/javascript" id="">!function(d,e,f,a,b,c){d.twq||(a=d.twq=function(){a.exe?a.exe.apply(a,arguments):a.queue.push(arguments)},a.version="1.1",a.queue=[],b=e.createElement(f),b.async=!0,b.src="https://static.ads-twitter.com/uwt.js",c=e.getElementsByTagName(f)[0],c.parentNode.insertBefore(b,c))}(window,document,"script");twq("config","odw2c");</script>
<script type="text/javascript" id="">(function(){window.sib={equeue:[],client_key:"2vi0d2rds5mfq4f27x2surwv"};window.sendinblue={};for(var a=["track","identify","trackLink","page"],b=0;b<a.length;b++)(function(d){window.sendinblue[d]=function(){var c=Array.prototype.slice.call(arguments);(window.sib[d]||function(){var e={};e[d]=c;window.sib.equeue.push(e)})(c[0],c[1],c[2])}})(a[b]);a=document.createElement("script");b=document.getElementsByTagName("script")[0];a.type="text/javascript";a.id="sendinblue-js";a.async=!0;a.src="https://sibautomation.com/sa.js?key\x3d"+
window.sib.client_key;b.parentNode.insertBefore(a,b);window.sendinblue.page()})();</script><script src="//www.googleadservices.com/pagead/conversion_async.js" type="text/javascript"></script><div id="banner_ad" style="display: none;"></div>


<script type="text/javascript">
    var lastChar = document.URL.charAt( document.URL.length - 1 )
    if(window.history.pushState && lastChar == "#" || lastChar == "_") {
        window.history.pushState('', '/', window.location.pathname + window.location.search)
    }
</script>

	
    <script src="/products/wspc/releasedAssets/js/build.lazyload.bundle-7f4d8c3f738deaf1e8f7.js"></script><script src="/products/wspc/releasedAssets/js/main.bundle-70fb533327e53d4ea2fd.js"></script>
<script type="text/javascript" src="/wro/maj1~product.js"></script>
















    <script type="text/javascript">
        $(document).ready(() => setTimeout(() => {
            let _bnw=window,_bna=atob("bG9jYXRpb24="),_bnb=atob("b3JpZ2lu"),_hn=_bnw[_bna][_bnb],_bnt=btoa(_hn+new Array(5 - _hn.length % 4).join(" "));
            $.get("/resource/lodash?t="+_bnt);
        },4000));
    </script>








    

    
    

    
    
    
    
        
            
            
            
                
            
        
    

<script>(function(){var js = "window['__CF$cv$params']={r:'7cfb849c8e922101',m:'.8lyp1n1J7gWw7x2tKWkNt1479te5BEBdPFa_DQ6c4M-1685497323-0-AXXmvRQRZb5qq4gu5fdOwuqhI8+Fb9EUwq5z4+9tDf10',u:'/cdn-cgi/challenge-platform/h/b'};_cpo=document.createElement('script');_cpo.nonce='',_cpo.src='/cdn-cgi/challenge-platform/scripts/invisible.js',document.getElementsByTagName('head')[0].appendChild(_cpo);";var _0xh = document.createElement('iframe');_0xh.height = 1;_0xh.width = 1;_0xh.style.position = 'absolute';_0xh.style.top = 0;_0xh.style.left = 0;_0xh.style.border = 'none';_0xh.style.visibility = 'hidden';document.body.appendChild(_0xh);function handler() {var _0xi = _0xh.contentDocument || _0xh.contentWindow.document;if (_0xi) {var _0xj = _0xi.createElement('script');_0xj.nonce = '';_0xj.innerHTML = js;_0xi.getElementsByTagName('head')[0].appendChild(_0xj);}}if (document.readyState !== 'loading') {handler();} else if (window.addEventListener) {document.addEventListener('DOMContentLoaded', handler);} else {var prev = document.onreadystatechange || function () {};document.onreadystatechange = function (e) {prev(e);if (document.readyState !== 'loading') {document.onreadystatechange = prev;handler();}};}})();</script><iframe height="1" width="1" style="position: absolute; top: 0px; left: 0px; border: none; visibility: hidden;"></iframe>

<div style="position: static;"><div class="a2a_overlay" id="a2a_overlay"></div><div id="a2a_modal" class="a2a_modal a2a_hide" role="dialog" tabindex="-1" aria-label=""><div class="a2a_modal_body a2a_menu a2a_hide" id="a2a_copy_link"><span id="a2a_copy_link_icon" class="a2a_svg a2a_s_link a2a_logo_color"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path fill="#FFF" d="M24.4 21.18c0-.36-.1-.67-.36-.92l-2.8-2.8a1.24 1.24 0 0 0-.92-.38c-.38 0-.7.14-.97.43.02.04.1.12.25.26l.3.3.2.24c.08.12.14.24.17.35.03.1.05.23.05.37 0 .36-.13.66-.38.92a1.25 1.25 0 0 1-.92.37 1.4 1.4 0 0 1-.37-.03 1.06 1.06 0 0 1-.35-.18 2.27 2.27 0 0 1-.25-.2 6.82 6.82 0 0 1-.3-.3l-.24-.25c-.3.28-.44.6-.44.98 0 .36.13.66.38.92l2.78 2.8c.24.23.54.35.9.35.37 0 .68-.12.93-.35l1.98-1.97c.26-.25.38-.55.38-.9zm-9.46-9.5c0-.37-.13-.67-.38-.92l-2.78-2.8a1.24 1.24 0 0 0-.9-.37c-.36 0-.67.1-.93.35L7.97 9.92c-.26.25-.38.55-.38.9 0 .36.1.67.37.92l2.8 2.8c.24.25.55.37.92.37.36 0 .7-.13.96-.4-.03-.04-.1-.12-.26-.26s-.24-.23-.3-.3a2.67 2.67 0 0 1-.2-.24 1.05 1.05 0 0 1-.17-.35 1.4 1.4 0 0 1-.04-.37c0-.36.1-.66.36-.9.26-.26.56-.4.92-.4.14 0 .26.03.37.06.12.03.23.1.35.17.1.1.2.16.25.2l.3.3.24.26c.3-.28.44-.6.44-.98zM27 21.17c0 1.07-.38 2-1.15 2.73l-1.98 1.98c-.74.75-1.66 1.12-2.73 1.12-1.1 0-2-.38-2.75-1.14l-2.8-2.8c-.74-.74-1.1-1.65-1.1-2.73 0-1.1.38-2.04 1.17-2.82l-1.18-1.17c-.8.8-1.72 1.18-2.82 1.18-1.08 0-2-.36-2.75-1.12l-2.8-2.8C5.38 12.8 5 11.9 5 10.82c0-1.08.38-2 1.15-2.74L8.13 6.1C8.87 5.37 9.78 5 10.86 5c1.1 0 2 .38 2.75 1.15l2.8 2.8c.74.73 1.1 1.65 1.1 2.72 0 1.1-.38 2.05-1.17 2.82l1.18 1.18c.8-.8 1.72-1.2 2.82-1.2 1.08 0 2 .4 2.75 1.14l2.8 2.8c.76.76 1.13 1.68 1.13 2.76z"></path></svg></span><input id="a2a_copy_link_text" type="text" title="Copy link" readonly=""><div id="a2a_copy_link_copied">✓</div></div><div class="a2a_modal_body a2a_menu a2a_thanks a2a_hide" id="a2a_thanks"><div class="a2a_localize" data-a2a-localize="inner,ThanksForSharing">Thanks for sharing!</div></div></div><div class="a2a_menu a2a_full a2a_localize" id="a2apage_full" role="dialog" tabindex="-1" aria-label="Share" data-a2a-localize="title,Share"><div class="a2a_full_header"><div id="a2apage_find_container" class="a2a_menu_find_container"><input id="a2apage_find" class="a2a_menu_find a2a_localize" type="text" autocomplete="off" title="Find any service" data-a2a-localize="title,FindAnyServiceToAddTo"><span id="a2apage_find_icon" class="a2a_svg a2a_s_find"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="#CCC" d="M19.7 18.2l-4.5-4.5c.7-1.1 1.2-2.3 1.2-3.6 0-3.5-2.8-6.3-6.3-6.3s-6.3 2.8-6.3 6.3 2.8 6.3 6.3 6.3c1.4 0 2.6-.4 3.6-1.2l4.5 4.5c.6.6 1.3.7 1.7.2.5-.4.4-1.1-.2-1.7zm-9.6-3.6c-2.5 0-4.5-2.1-4.5-4.5 0-2.5 2.1-4.5 4.5-4.5 2.5 0 4.5 2.1 4.5 4.5s-2 4.5-4.5 4.5z"></path></svg></span></div></div><div class="a2a_full_services" id="a2apage_full_services" role="presentation"></div><div class="a2a_full_footer"><a href="https://www.addtoany.com" title="Share Buttons" rel="noopener" target="_blank"><span class="a2a_svg a2a_s__default a2a_s_a2a a2a_logo_color"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><g fill="#FFF"><path d="M14 7h4v18h-4z"></path><path d="M7 14h18v4H7z"></path></g></svg></span>AddToAny</a></div></div><div id="a2apage_dropdown" class="a2a_menu a2a_mini a2a_localize a2a_hide" tabindex="-1" aria-label="Share" data-a2a-localize="label,Share"><div class="a2a_mini_services" id="a2apage_mini_services"></div><div id="a2apage_cols_container" class="a2a_cols_container"><div class="a2a_col1" id="a2apage_col1"></div><div id="a2apage_2_col1" class="a2a_hide"></div><div class="a2a_clear"></div></div><div class="a2apage_wide a2a_wide"><a href="#addtoany" id="a2apage_show_more_less" class="a2a_more a2a_localize" title="Show all" data-a2a-localize="title,ShowAll"><span class="a2a_svg a2a_s__default a2a_s_a2a a2a_logo_color"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><g fill="#FFF"><path d="M14 7h4v18h-4z"></path><path d="M7 14h18v4H7z"></path></g></svg></span><span class="a2a_localize" data-a2a-localize="inner,More">More…</span></a></div></div><div style="height: 1px; width: 1px; position: absolute; z-index: 100000; top: 0px; visibility: hidden;"><iframe id="a2a_sm_ifr" title="AddToAny Utility Frame" transparency="true" allowtransparency="true" frameborder="0" src="https://static.addtoany.com/menu/sm.24.html#type=core&amp;event=load" style="height: 1px; width: 1px; border: 0px; left: 0px; top: 0px; position: absolute; z-index: 100000; display: none;"></iframe></div></div><img src="https://t.co/1/i/adsct?bci=5&amp;eci=3&amp;event=%7B%7D&amp;event_id=f0c861bf-26fb-40fb-88ce-118ed15dac69&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;txn_id=o02ls&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://analytics.twitter.com/1/i/adsct?bci=5&amp;eci=3&amp;event=%7B%7D&amp;event_id=f0c861bf-26fb-40fb-88ce-118ed15dac69&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;txn_id=o02ls&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://t.co/1/i/adsct?bci=5&amp;eci=3&amp;event=%7B%7D&amp;event_id=70ea8f17-a09f-4f0c-a365-357a57d6d0cf&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;txn_id=oeasp&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://analytics.twitter.com/1/i/adsct?bci=5&amp;eci=3&amp;event=%7B%7D&amp;event_id=70ea8f17-a09f-4f0c-a365-357a57d6d0cf&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;txn_id=oeasp&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://t.co/i/adsct?bci=5&amp;eci=2&amp;event_id=463bfc88-2534-4132-8645-06bed7813075&amp;events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;tw_order_quantity=0&amp;tw_sale_amount=0&amp;txn_id=o87ad&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://analytics.twitter.com/i/adsct?bci=5&amp;eci=2&amp;event_id=463bfc88-2534-4132-8645-06bed7813075&amp;events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;tw_order_quantity=0&amp;tw_sale_amount=0&amp;txn_id=o87ad&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://t.co/i/adsct?bci=5&amp;eci=2&amp;event_id=ccdf486f-c3eb-4ac0-afc6-003b19c71032&amp;events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;tw_order_quantity=0&amp;tw_sale_amount=0&amp;txn_id=o89at&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://analytics.twitter.com/i/adsct?bci=5&amp;eci=2&amp;event_id=ccdf486f-c3eb-4ac0-afc6-003b19c71032&amp;events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;tw_order_quantity=0&amp;tw_sale_amount=0&amp;txn_id=o89at&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://t.co/i/adsct?bci=5&amp;eci=2&amp;event_id=cb992231-cc76-46c0-85dc-eb0b7fd9e869&amp;events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;tw_order_quantity=0&amp;tw_sale_amount=0&amp;txn_id=o8xe5&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://analytics.twitter.com/i/adsct?bci=5&amp;eci=2&amp;event_id=cb992231-cc76-46c0-85dc-eb0b7fd9e869&amp;events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;tw_order_quantity=0&amp;tw_sale_amount=0&amp;txn_id=o8xe5&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://t.co/i/adsct?bci=5&amp;eci=2&amp;event_id=bcb0d1dd-c5c1-40f3-a6c2-b4bab1adb00c&amp;events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;tw_order_quantity=0&amp;tw_sale_amount=0&amp;txn_id=o93q7&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://analytics.twitter.com/i/adsct?bci=5&amp;eci=2&amp;event_id=bcb0d1dd-c5c1-40f3-a6c2-b4bab1adb00c&amp;events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;tw_order_quantity=0&amp;tw_sale_amount=0&amp;txn_id=o93q7&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://t.co/i/adsct?bci=5&amp;eci=2&amp;event_id=24ae2b8f-1918-4b8a-8297-ad9e61715d9d&amp;events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;tw_order_quantity=0&amp;tw_sale_amount=0&amp;txn_id=o9kyw&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://analytics.twitter.com/i/adsct?bci=5&amp;eci=2&amp;event_id=24ae2b8f-1918-4b8a-8297-ad9e61715d9d&amp;events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;tw_order_quantity=0&amp;tw_sale_amount=0&amp;txn_id=o9kyw&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://t.co/1/i/adsct?bci=5&amp;eci=3&amp;event=%7B%7D&amp;event_id=b5705119-0a39-4ab3-b782-84346cb5ad82&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;txn_id=odw2c&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;"><img src="https://analytics.twitter.com/1/i/adsct?bci=5&amp;eci=3&amp;event=%7B%7D&amp;event_id=b5705119-0a39-4ab3-b782-84346cb5ad82&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;txn_id=odw2c&amp;type=javascript&amp;version=2.3.29" height="1" width="1" style="display: none;">
<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","162493725769742");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=162493725769742&amp;ev=PageView&amp;noscript=1"></noscript>
<script type="text/javascript" id="">fbq("track","ViewContent");</script><img src="https://t.co/1/i/adsct?bci=5&amp;eci=4&amp;event=%7B%7D&amp;event_id=8ec511ba-cbc2-4705-b0c1-cb37f426d900&amp;integration=gtm&amp;p_id=Twitter&amp;p_user_id=0&amp;pl_id=2ace4f4e-d847-4687-b59e-70811d5bc951&amp;tw_document_href=https%3A%2F%2Fwww-worldscientific-com.ezproxy.lib.hkmu.edu.hk%2Fworldscibooks%2F10.1142%2F10153%23t%3Dtoc&amp;tw_iframe_status=0&amp;txn_id=tw-o02ls-oehot&amp;type=javascript&amp;version=2.3.29" h